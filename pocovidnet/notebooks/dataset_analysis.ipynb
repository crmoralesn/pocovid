{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report numbers of each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/dataset_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubs = data[~pd.isnull(data[\"DOI\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online1 = data[pd.isnull(data[\"DOI\"])]\n",
    "online = online1[online1[\"Filename\"].str.contains(\"Avi\")]\n",
    "online2 = online1[online1[\"Filename\"].str.contains(\"orthumbr\")]\n",
    "# online = online[~online[\"Filename\"].str.contains(\"olzano\")]\n",
    "# online = online[~online[\"URL (Video Name)\"].str.contains(\"lotte\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label = [f[:3].lower() for f in online[\"Filename\"]]\n",
    "label2 = [f[:3].lower() for f in online2[\"Filename\"]]\n",
    "np.unique(label, return_counts = True), np.unique(label2, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pubs), np.unique(pubs[\"Type\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pathologies plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(fn):\n",
    "    if fn.lower() in [\"reg\", \"cov\", \"pne\", \"vir\"]:\n",
    "        return fn.lower()\n",
    "    else:\n",
    "        print(fn)\n",
    "        return \"reg\" # all wrong ones are reg write now\n",
    "label = [filter_fn(fn[:3]) for fn in data[\"Filename\"].values] #  if fn[:3] in [\"Reg\", \"reg\", \"Cov\", \"cov\", \"pne\", \"Pne\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# effusion, consolidated, blines, alines, irregular = [], [], [], []\n",
    "found_pattern = np.array([\"(sub)pleural effusion\", \"consolidation\", \"B-line(s)\", \"A-lines\", \"irregular pleural line\", \"air bronchogram\", \"normal\"])\n",
    "pathologies = np.zeros((len(data), 7))\n",
    "pat_dict = [[\"effusion\"], [\"consol\"], [\"b line\", \"b-line\", \"b - line\"], [\"a line\", \"a-line\", \"a - line\"], \n",
    "            [\"pleural irregular\", \"irregular pleural\", \"pleural thickening\"], [\"bronchogram\"],\n",
    "            [\"normal\", \"healthy\"]]\n",
    "\n",
    "skipped = []\n",
    "for i, row in data.iterrows():\n",
    "    if \"artifacts\" in row[\"Current location\"] or \"uncertain\" in row[\"Current location\"] or  \"not\" in row[\"Current location\"].lower():\n",
    "        #  print(\"ueberspringe\", row[\"Filename\"])\n",
    "        skipped.append(i)\n",
    "        continue\n",
    "    all_comments = (str(row['Comments first medical doctor (MD1)']) + \" \" +  str(row['MD2']) + \" \" +  str(row['Comments from web site'])).lower()\n",
    "    # Effusion?\n",
    "    for pat_ind in range(7):\n",
    "        for pat in pat_dict[pat_ind]:\n",
    "            if (not \"no \"+pat in all_comments) and (not \"not \"+ pat in all_comments) and pat in all_comments:\n",
    "                pathologies[i,pat_ind] = 1\n",
    "    # print(str(row['Comments first medical doctor (MD1)'])+ \" \" + str(row['MD2']))\n",
    "    one_pathologies = np.where(pathologies[i]>0)[0]\n",
    "    # print(found_pattern[one_pathologies])\n",
    "    # print( row[\"Current location\"])\n",
    "    ## check abnormal healthy\n",
    "    # if (row[\"Filename\"]).lower()[:3]==\"reg\" and (\"effusion\" in all_comments or \"consol\" in all_comments or \"pleural irregular\" in all_comments):\n",
    "    #    print(row[\"Filename\"].lower())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pathologies = np.delete(pathologies, skipped, axis=0)\n",
    "filtered_labels = np.delete(label, skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mddf = pd.DataFrame(filtered_pathologies.astype(int), columns = found_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mddf.to_csv(\"../../data/pathologies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mddf[\"label\"] = filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = mddf.groupby(\"label\").aggregate(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview.index[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Main plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # the label locations\n",
    "width = 0.7  # the width of the bars\n",
    "num = len(found_pattern)\n",
    "x = np.arange(4)\n",
    "\n",
    "uni, counts = np.unique(mddf[\"label\"].values, return_counts=True)\n",
    "xtick_labs = [\"COVID-19\", \"Bacterial pneu.\", \"Healthy\", \"Viral pneu.\"]\n",
    "new_xtick_labs = []\n",
    "for i in range(4):\n",
    "    new_xtick_labs.append(xtick_labs[i]+\"\\n (n=\"+str(int(counts[i]))+\")\")\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "rects = list()\n",
    "for i in range(num):\n",
    "    rect = ax.bar(x - width/2 + (i+1)*width/num, overview[found_pattern[i]].values, width/num, label=found_pattern[i])\n",
    "    rects.append(rect)\n",
    "# rects2 = ax.bar(x + width/4, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Pathology occurence (%)', fontsize=30)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(new_xtick_labs, fontsize=26,) #  rotation=5)\n",
    "ax.legend(fontsize=22.2,loc='upper right', bbox_to_anchor=(1, 1.02), ncol=3, framealpha=0.5) # bbox_to_anchor=(0.25, 0.16, 0.81, 0.88)\n",
    "ax.set_ylim(0,1.02)\n",
    "ax.set_yticklabels(range(0,101, 20),fontsize=23)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../../pocovidnet/results_oct/plots/pathologies.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 79/261"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the other way round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(overview.columns))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "rects = list()\n",
    "for i in range(4):\n",
    "    rect = ax.bar(x - width/2 + i*width/4, overview.iloc[i].values, width/4, label=overview.index[i])\n",
    "    rects.append(rect)\n",
    "# rects2 = ax.bar(x + width/4, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Occurences in comments of medical experts', fontsize=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(found_pattern, fontsize=20)\n",
    "ax.legend(fontsize=20)\n",
    "ax.set_ylim(0,0.8)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = [float(fr) for fr in data_vids[\"Framerate\"].values if fr is not None and ~np.isnan(float(fr))]\n",
    "print(\"avg framerate\", np.mean(fr), np.std(fr), np.min(fr), np.max(fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vids = data[data[\"Type\"]==\"video\"]\n",
    "print(\"Average number of frames and std\")\n",
    "np.nanmean(data_vids[\"Length (frames)\"]), np.nanstd(data_vids[\"Length (frames)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_nan(data):\n",
    "    return np.array([d for d in data if not pd.isnull(d) and d!=\"n/A\" and d!=\"nd\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnan_ages = not_nan(data[\"Age\"]).astype(int) # data[np.logical_and(~pd.isnull(data[\"Age\"]), data[\"Age\"]!=\"n/A\")]\n",
    "print(\"Age filled in for \", len(notnan_ages)/len(data), \"% (len data:\", len(data))\n",
    "sns.distplot(notnan_ages)\n",
    "plt.xlabel(\"Patient age\", fontsize=15)\n",
    "plt.yticks([])\n",
    "plt.savefig(\"../results_oct/plots/age_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(notnan_ages), np.mean(notnan_ages), np.std(notnan_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = not_nan(data[\"Gender\"])\n",
    "print(\"Gender filled in for\", round(len(gender)/ len(data), 2), \"%\")\n",
    "print(np.unique(gender, return_counts=True))\n",
    "print(np.sum(gender==\"m\") / len(gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_cols = ['Current location', 'Fever','Cough', 'Respiratory problems', 'Headache', 'Fatigue', 'Asymptomatic']\n",
    "# 'Sore throat', , 'Loss of smell/taste',\n",
    "symptoms = data[symptom_cols]\n",
    "# convert labels to int\n",
    "labs_uni = list(np.unique(label))\n",
    "label_int = [labs_uni.index(l) for l in label]\n",
    "symptoms[\"label\"] = label_int\n",
    "symptoms = symptoms.dropna()\n",
    "# drop all that have no symptom at all\n",
    "symptoms = symptoms[symptoms[\"Fever\"]!=\"n/A\"]\n",
    "symptoms = symptoms[~symptoms[\"Current location\"].str.contains(\"not\")]\n",
    "symptoms = symptoms[~symptoms[\"Current location\"].str.contains(\"Not\")]\n",
    "symptoms = symptoms[~symptoms[\"Current location\"].str.contains(\"artifacts\")]\n",
    "# print(list(symptoms[\"Current location\"]))\n",
    "symptoms = symptoms.drop(columns=[\"Current location\"])\n",
    "symptom_cols = symptom_cols[1:]\n",
    "for col in symptom_cols:\n",
    "    symptoms.loc[symptoms[col]==\"n/A\", col] = 0\n",
    "symptoms = symptoms.astype(int)\n",
    "# symptoms = symptoms[cols].apply(pd.to_numeric)\n",
    "# symptoms = symptoms.where(symptoms == \"n/A\", \"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(symptoms) / len(filtered_pathologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_grouped = symptoms.groupby(\"label\").aggregate(\"mean\")\n",
    "\n",
    "uni, counts = np.unique(symptoms[\"label\"].values, return_counts=True)\n",
    "xtick_labs = [\"COVID-19\", \"Bacterial pneu.\", \"Healthy\", \"Viral pneu.\"]\n",
    "new_xtick_labs = []\n",
    "for i in range(4):\n",
    "    new_xtick_labs.append(xtick_labs[i]+\"\\n (n=\"+str(int(counts[i]))+\")\")\n",
    "\n",
    "# the label locations\n",
    "width = 0.7  # the width of the bars\n",
    "num = len(symptom_cols)\n",
    "x = np.arange(4)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "rects = list()\n",
    "for i in range(num):\n",
    "    rect = ax.bar(x - width/2 + (i+1)*width/num, symptoms_grouped[symptom_cols[i]].values, width/num, label=symptom_cols[i])\n",
    "    rects.append(rect)\n",
    "# rects2 = ax.bar(x + width/4, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Reported symptoms (%)', fontsize=30)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(new_xtick_labs, fontsize=26)\n",
    "ax.legend(fontsize=24, loc=\"upper left\", bbox_to_anchor=(.05, 1.02), ncol=2)\n",
    "ax.set_ylim(0,1.02)\n",
    "ax.set_yticklabels(range(0,101, 20),fontsize=23)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"../../pocovidnet/results_oct/plots/symptoms.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fever = (data[\"Fever\"]==\"1\").astype(int) * (np.array(label_int)==2).astype(int) > 0\n",
    "print(np.any(data_fever))\n",
    "data[data_fever]\n",
    "# np.logical_and(np.array(label_int)==2,  data[\"Respiratory problems\"]==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avi's data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avi = data[data[\"URL (Video Name)\"].str.contains(\"humbria\")]\n",
    "# data[np.logical_or(data[\"Filename\"].str.contains(\"Avi\"), data[\"Filename\"].str.contains(\"orthumbria\"))]\n",
    "avi_gender = avi[~pd.isnull(avi[\"Gender\"])]\n",
    "avi_gender = avi_gender[~avi_gender[\"Current location\"].str.contains(\"not\")]\n",
    "avi_gender = avi_gender[~avi_gender[\"Current location\"].str.contains(\"Not\")]\n",
    "avi_gender = avi_gender[~avi_gender[\"Current location\"].str.contains(\"artifacts\")]\n",
    "np.unique(avi_gender[\"Type\"], return_counts= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get numbers of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois = data[\"DOI\"]\n",
    "titles = data[~pd.isnull(dois)]\n",
    "list(np.unique(titles[\"Title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"Title\"]==\"Usefulness of lung ultrasound in diagnosing causes of exacerbation in patients with chronic dyspnea\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_image = data[data[\"Type\"]==\"image\"]\n",
    "data_image = data_image[data_image[\"URL (Video Name)\"].str.contains(\"humbria\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"not\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"Not\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"artifacts\")]\n",
    "data_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = data[data[\"Type\"]==\"image\"]\n",
    "data_image[data[\"Probe\"]==\"convex\"]\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET WEB VIDEOS\n",
    "data_image = data[data[\"Type\"]==\"image\"]\n",
    "data_image = data_image[pd.isnull(data_image[\"DOI\"])]\n",
    "data_image = data_image[~data_image[\"Filename\"].str.contains(\"Avi\")]\n",
    "data_image = data_image[~data_image[\"Filename\"].str.contains(\"olzano\")]\n",
    "data_image = data_image[~data_image[\"Filename\"].str.contains(\"orthumbria\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"utterfly\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"not\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"Not\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"artifacts\")]\n",
    "data_image = data_image[~data_image[\"URL (Video Name)\"].str.contains(\"atlas\")]\n",
    "data_image = data_image[~data_image[\"URL (Video Name)\"].str.contains(\"grepmed\")]\n",
    "data_image = data_image[~data_image[\"URL (Video Name)\"].str.contains(\"litfl\")]\n",
    "data_image = data_image[~data_image[\"URL (Video Name)\"].str.contains(\"charlotte\")]\n",
    "data_image\n",
    "# data_image[~pd.isnull(data_image[\"DOI\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = data[data[\"Type\"]==\"video\"]\n",
    "data_image= data_image[data_image[\"Probe\"]==\"linear\"]\n",
    "data_image = data_image[~data_image[\"Filename\"].str.contains(\"olzano\")]\n",
    "data_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET publications videos and images\n",
    "data_image = data[data[\"Type\"]==\"video\"]\n",
    "data_image = data_image[~pd.isnull(data_image[\"DOI\"])]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"not\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"Not\")]\n",
    "data_image = data_image[~data_image[\"Current location\"].str.contains(\"artifacts\")]\n",
    "data_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grep\n",
    "data_notnan = data[~pd.isnull(data[\"URL (Video Name)\"])]\n",
    "data_notnan[data_notnan[\"URL (Video Name)\"].str.contains(\"grep\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_files = data[data[\"License\"]==\"None\"]\n",
    "for name, path in zip(rm_files[\"Filename\"], rm_files[\"Current location\"]):\n",
    "    if path.startswith(\"data\"):\n",
    "        new_path = path[5:]\n",
    "    else:\n",
    "        new_path = path\n",
    "    if \"butterfly\" in new_path or \"not\" in new_path:\n",
    "        continue\n",
    "    print(f'rm \"{new_path.lower()}/{name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../data/crop.json\", \"r\") as infile:\n",
    "    crop = json.load(infile)\n",
    "for key in crop.keys():\n",
    "    print(\"data/\"+key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git rm data/pocus_images/convex/Cov_ablines_covidmanifestations_paper1.png\n",
    "git rm data/pocus_images/convex/Cov_blines_covidmanifestation_paper2.png\n",
    "git rm data/pocus_images/linear/Cov_irregularpleural_covidmanifestations_paper3.png\n",
    "git rm data/pocus_videos/convex/Reg-nephropocus.mp4\n",
    "git rm data/pocus_videos/linear/Reg-NormalLung.mp4\n",
    "git rm data/pocus_images/linear/Cov_blines_acutemedicine.png\n",
    "git rm data/pocus_images/convex/Reg_bikus.png\n",
    "git rm data/pocus_images/convex/Pneu_bikus2.png\n",
    "git rm data/pocus_images/convex/Pneu_bikus3.png\n",
    "git rm data/pocus_images/convex/Reg_acutemedicine.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path1 = \"../../data/\"\n",
    "path2 = \"/Users/ninawiedemann/Projects/backup_covid19_pocus_ultrasound/data/\"\n",
    "for modality in [\"convex\", \"linear\"]:\n",
    "    for datatype in [\"videos\", \"images\"]:\n",
    "        path_new = os.path.join(path1, \"pocus_\" + datatype, modality)\n",
    "        path_old = os.path.join(path2, \"pocus_\" + datatype, modality)\n",
    "        print(\"---------\", modality, datatype)\n",
    "        new_files = os.listdir(path_new)\n",
    "        old_files = os.listdir(path_old)\n",
    "        print(\"\\n not in old \\n\")\n",
    "        for f in new_files:\n",
    "            fn_gif = f.split(\".\")[0]+\".gif\"\n",
    "            fn_avi = f.split(\".\")[0]+\".avi\"\n",
    "            fn_mov = f.split(\".\")[0]+\".mov\"\n",
    "            if f not in old_files and fn_gif not in old_files and fn_avi not in old_files and fn_mov not in old_files:\n",
    "                print(f)\n",
    "        print(\"\\n not in new \\n\")\n",
    "        for f in old_files:\n",
    "            fn_mp4 = f.split(\".\")[0]+\".mp4\"\n",
    "            if f not in new_files and fn_mp4 not in new_files and \"utterfly\" not in f:\n",
    "                print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print without filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/dataset_metadata.csv\")\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column = \"Length (frames)\"\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    loc = row[\"Current location\"].lower()\n",
    "    if loc.startswith(\"data\"):\n",
    "        loc = loc[5:]\n",
    "    filename_without = row[\"Filename\"].split(\".\")[0]\n",
    "    \n",
    "    # if row[\"Filename\"][-3:] in [\"png\", \"jpg\"]:\n",
    "    #     print(1)\n",
    "    #     continue\n",
    "    \n",
    "    if os.path.exists(os.path.join(\"../../data/\", loc, row[\"Filename\"])):\n",
    "        path = os.path.join(\"../../data/\", loc, row[\"Filename\"])\n",
    "    elif os.path.exists(os.path.join(\"../../data/\", loc, filename_without+\".mp4\")):\n",
    "        path = os.path.join(\"../../data/\", loc, filename_without+\".mp4\")\n",
    "    else:\n",
    "        if pd.isnull(row[column]) or row[column]==\"-\":\n",
    "            print(\"n/a\")\n",
    "        else:\n",
    "            print(row[column])\n",
    "        continue\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    # print(filename_without)\n",
    "    # print(round(cap.get(5)))\n",
    "    # print(f\"{round(cap.get(3))}x{round(cap.get(4))}\")\n",
    "    print(int(cap.get(7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
