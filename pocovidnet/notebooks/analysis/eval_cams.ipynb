{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class activation map evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pocovidnet.evaluate_covid19 import Evaluator\n",
    "from pocovidnet.grad_cam import GradCAM\n",
    "from pocovidnet.cam import get_class_activation_map\n",
    "from pocovidnet.model import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to crop ICLUS videos automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(\"../../../../data_pocovid/results_oct_wrong_crossval/iclus/\", 'ICLUS_cropping.json'), \"r\") as infile:\n",
    "    frame_cut = json.load(infile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom = 70 #  90\n",
    "top = 570 # 542\n",
    "left = 470 # 480\n",
    "right = 970 # 932\n",
    "# [70:570, 470:970]\n",
    "crop = [bottom, top, left, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/ICLUS\"\n",
    "for subfolder in os.listdir(data_dir):\n",
    "    if \"linear\" in subfolder.lower() or subfolder.startswith(\".\") or not os.path.isdir(os.path.join(data_dir,subfolder)):\n",
    "        continue\n",
    "    for vid in os.listdir(os.path.join(data_dir, subfolder)):\n",
    "        vid_id = vid.split(\".\")[0]\n",
    "        if vid.startswith(\".\"):\n",
    "            continue\n",
    "        print(\"process next file \", vid)\n",
    "        if vid_id not in [\"40\", \"42\"]: # frame_cut.keys():\n",
    "            continue\n",
    "        video_path = os.path.join(data_dir, subfolder, vid)\n",
    "        crop = frame_cut[vid_id]\n",
    "        while True:\n",
    "            bottom, top, left, right = crop\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            # count = 0\n",
    "            # while cap.isOpened() and count< 1:\n",
    "            for _ in range(3):\n",
    "                ret, frame = cap.read()\n",
    "            plt.imshow(frame[bottom:top, left:right])\n",
    "            plt.show()\n",
    "            crop_in = input(\"okay?\")\n",
    "            if crop_in == 1 or crop_in ==\"1\":\n",
    "                frame_cut[vid_id] = crop\n",
    "                break\n",
    "            crop_in = input(\"input list \" + str(crop))\n",
    "            crop = eval(crop_in)\n",
    "            print(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_iclus_data = \"../results_oct/iclus\"\n",
    "with open(os.path.join(data_dir, 'ICLUS_cropping.json'), \"w\") as outfile:\n",
    "    json.dump(frame_cut, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICLUS Auswertung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = pd.read_csv(\"../../../data/iclus_severity.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convex_table = severity[severity[\"filename\"].str.contains(\"convex\")]\n",
    "convex_vids = convex_table[\"Video\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of IDs that we analyze\n",
    "data_dir = \"../../../data/ICLUS\"\n",
    "process_vid_numbers = []\n",
    "for subfolder in os.listdir(data_dir):\n",
    "    if \"linear\" in subfolder.lower() or subfolder.startswith(\".\") or os.path.isfile(os.path.join(data_dir,subfolder)):\n",
    "        continue\n",
    "    for vid in os.listdir(os.path.join(data_dir, subfolder)):\n",
    "        vid_id = vid.split(\".\")[0]\n",
    "        if vid.startswith(\".\"):\n",
    "            continue\n",
    "        video_path = os.path.join(data_dir, subfolder, vid)\n",
    "        \n",
    "        # print(int(vid.split(\".\")[0]) in convex_vids)\n",
    "        process_vid_numbers.append(int(vid.split(\".\")[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether we cover all videos\n",
    "for vid in convex_vids.values:\n",
    "    if vid not in process_vid_numbers:\n",
    "        print(\"In ICLUS tabelle but not in our folder:\", vid)\n",
    "    if str(vid) not in frame_cut.keys():\n",
    "        print(\"not in crop dict:\", vid)\n",
    "for vid in process_vid_numbers:\n",
    "    if vid not in convex_vids.values:\n",
    "        print(\"In our folder but not in ICLUS:\", vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make label dict:\n",
    "iclus_labels = dict(zip(convex_table[\"Video\"], convex_table[\"Score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = os.path.join(res_dir, f\"cam_{vid_id}.npy\")\n",
    "os.path.exists(in_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6 normal (Gabriel, but here 1), 25 normal (Gabriel), but here 3\n",
    "iclus_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with numpy files\n",
    "len(iclus_labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_dir = \"../../../../data_pocovid/results_oct_wrong_crossval/iclus/base\"\n",
    "gt, preds, pred_probs = list(), list(), list()\n",
    "print(\"gt   pred\")\n",
    "for vid_id in iclus_labels.keys():\n",
    "    in_path = os.path.join(res_dir, f\"cam_{vid_id}.npy\")\n",
    "    if not os.path.exists(in_path):\n",
    "        print(\"Warning: logits do not exist\", in_path)\n",
    "        continue\n",
    "    logits = np.load(in_path)\n",
    "    prob = np.mean(logits[:, 0])\n",
    "    avg_covid_prob = np.argmax(np.mean(logits, axis=0)) # \n",
    "    # print(avg_covid_prob)\n",
    "    gt.append(iclus_labels[vid_id])\n",
    "    pred_probs.append(prob)\n",
    "    preds.append(avg_covid_prob)\n",
    "    if iclus_labels[vid_id]>2 and avg_covid_prob==2 or iclus_labels[vid_id]==0 and avg_covid_prob==0:\n",
    "        print(\"wrong, severity is \", iclus_labels[vid_id], \"pred is\", avg_covid_prob,\"video:\", vid_id)\n",
    "    # print(gt[-1], preds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gt, pred_probs)\n",
    "plt.plot([0,3], [0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = \"../../models/cross_validation_neurips/\"\n",
    "file_list = list()\n",
    "for folder in os.listdir(check):\n",
    "    if folder[0] == \".\":\n",
    "        continue\n",
    "    for classe in os.listdir(os.path.join(check, folder)):\n",
    "        if classe[0] == \".\" or classe[0] == \"u\":\n",
    "            continue\n",
    "        uni = []\n",
    "        is_image = 0\n",
    "        for file in os.listdir(os.path.join(check, folder, classe)):\n",
    "            if file[0] == \".\":\n",
    "                continue\n",
    "            if len(file.split(\".\")) == 2:\n",
    "                is_image += 1\n",
    "            uni.append(file.split(\".\")[0])\n",
    "        file_list.extend(np.unique(uni).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../models/in_neurips.json\", \"w\") as outfile:\n",
    "    json.dump(file_list, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old video evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skvideo import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoEvaluator(Evaluator):\n",
    "    def __init__(self, weights_dir=\"../trained_models_cam\", ensemble=True, split=None, model_id=None, num_classes=3):\n",
    "        Evaluator.__init__(\n",
    "            self, ensemble=ensemble, split=split, model_id=model_id, num_classes=num_classes\n",
    "        )\n",
    "    \n",
    "    def __call__(self, video_path):\n",
    "        \"\"\"Performs a forward pass through the restored model\n",
    "\n",
    "        Arguments:\n",
    "            video_path: str -- file path to a video to process. Possibly types are mp4, gif, mpeg\n",
    "            return_cams: int -- number of frames to return with activation maps overlayed. If zero, \n",
    "\t\t\t\t\t\tonly the predictions will be returned. Always selects the frames with \n",
    "                        highest probability for the predicted class\n",
    "\n",
    "        Returns:\n",
    "        \tcams: if return_cams>0, images with overlay are returned as a np.array of shape\n",
    "            \t\t{number models} x {return_cams} x 224 x 224 x 3\n",
    "            mean_preds: np array of shape {video length} x {number classes}. Contains\n",
    "            \t\t\tclass probabilities per frame\n",
    "        \"\"\"\n",
    "\n",
    "        self.image_arr = self.read_video(video_path)\n",
    "        self.predictions = np.stack([model.predict(self.image_arr) for model in self.models])\n",
    "        \n",
    "        mean_preds = np.mean(self.predictions, axis=0, keepdims=False)\n",
    "        class_idx = np.argmax(np.mean(np.array(mean_preds), axis=0))\n",
    "        \n",
    "        return mean_preds\n",
    "    \n",
    "    def cam_important_frames(self, class_idx, threshold=0.5, nr_cams=None, zeroing=0.65, save_video_path=None): # \"out_video.mp4\"):\n",
    "        mean_preds = np.mean(self.predictions, axis=0, keepdims=False)\n",
    "        # compute general video class\n",
    "        # class_idx = np.argmax(np.mean(np.array(mean_preds), axis=0))\n",
    "        prediction = np.argmax(np.mean(np.array(mean_preds), axis=0))\n",
    "        print(\"predicted\", prediction, \"gt\", class_idx)\n",
    "        print(\"pred probs covid\", [round(m, 2) for m in mean_preds[:,0]])\n",
    "        # get most important frames (the ones above threshold)\n",
    "        if nr_cams is not None:\n",
    "            best_frames = np.argsort(mean_preds[:, class_idx])[-nr_cams:]\n",
    "        else:\n",
    "            best_frames = np.where(mean_preds[:, class_idx]>threshold)[0]\n",
    "        # best_frames = np.arange(len(mean_preds))\n",
    "        print(\"frames above threshold\", best_frames)\n",
    "        return_cams = len(best_frames)\n",
    "\n",
    "        if len(best_frames)==0:\n",
    "            print(\"no frame above threshold\")\n",
    "            return 0\n",
    "            \n",
    "        # copy image arr - need values between 0 and 255\n",
    "        copied_arr = (self.image_arr.copy() * 255).astype(int)\n",
    "\n",
    "        cams = np.zeros((return_cams, 224, 224, 3))\n",
    "        for j, b_frame in enumerate(best_frames):\n",
    "            # get highest prob model for these frames\n",
    "            model_idx = np.argmax(self.predictions[:, b_frame, class_idx], axis=0)\n",
    "            take_model = self.models[model_idx]\n",
    "            if \"cam\" in self.model_id:\n",
    "                in_img = np.expand_dims(self.image_arr[b_frame], 0)\n",
    "                # print(in_img.shape)\n",
    "                cams[j] = get_class_activation_map(take_model, in_img, class_idx, image_weight=1, zeroing=zeroing).astype(int)\n",
    "            else:\n",
    "                # run grad cam for other models\n",
    "                gradcam = GradCAM()\n",
    "                cams[j] = gradcam.explain(self.image_arr[b_frame], take_model, class_idx, return_map=False,image_weight=1, layer_name=\"block5_conv3\", zeroing=zeroing, heatmap_weight=0.25)\n",
    "                \n",
    "        if save_video_path is None:\n",
    "            return cams\n",
    "        else:\n",
    "            for j in range(return_cams):\n",
    "                copied_arr[best_frames[j]] = cams[j]\n",
    "            copied_arr = np.repeat(copied_arr, 3, axis=0)\n",
    "            io.vwrite(save_video_path+\".mpeg\", copied_arr, outputdict={\"-vcodec\":\"mpeg2video\"})\n",
    "        \n",
    "    def read_video(self, video_path):\n",
    "        assert os.path.exists(video_path), \"video file not found\"\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        images = []\n",
    "        counter = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if (ret != True):\n",
    "                break\n",
    "            if counter<1:\n",
    "                plt.imshow(frame[30:360, 100:430]) # ICLUS: [70:570, 470:970]) # [25:350, 100:425]) # LOTTE:[30:400, 80:450]\n",
    "                plt.show()\n",
    "                counter += 1\n",
    "                continue\n",
    "            counter += 1\n",
    "            img_processed = self.preprocess(frame)[0]\n",
    "            images.append(img_processed)\n",
    "        cap.release()\n",
    "        return np.array(images)\n",
    "    \n",
    "    def preprocess(self, image, cut=True):\n",
    "        \"\"\"Apply image preprocessing pipeline\n",
    "\n",
    "        Arguments:\n",
    "            image {np.array} -- Arbitrary shape, quadratic preferred\n",
    "\n",
    "        Returns:\n",
    "            np.array -- Shape 224,224. Normalized to [0, 1].\n",
    "        \"\"\"\n",
    "        if cut:\n",
    "            image = image[30:360, 100:430]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = np.expand_dims(np.array(image), 0) / 255.0\n",
    "        return image\n",
    "    \n",
    "    def important_frames(self, preds, predicted_class, n_return=5):\n",
    "        preds_arr = np.array(preds)\n",
    "        frame_scores = preds_arr[:, predicted_class]\n",
    "        best_frames = np.argsort(frame_scores)[-n_return:]\n",
    "        return best_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator = VideoEvaluator(ensemble=True, model_id=\"vgg_cam\", num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ICLUS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_plot(preds, save_path):\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.plot(preds[:,0], label=\"covid\")\n",
    "    plt.plot(preds[:,1], label=\"pneu\")\n",
    "    plt.plot(preds[:,2], label=\"healthy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path+\".png\")\n",
    "    plt.show()\n",
    "# plt.plot(preds[:,1], label=\"pneu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iclus_dir = \"Videos_31_to_40\"\n",
    "iclus_dir = \"test_data_regular/pat2\"\n",
    "# iclus_dir = \"data/pocus_videos/convex/\"\n",
    "# out_iclus_data = \"vids_preds_regular_test\"\n",
    "# out_iclus_data = \"vids_preds_iclus\"\n",
    "out_iclus_data = \"reg_test/pat2\"\n",
    "GT_CLASS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for vid in os.listdir(iclus_dir):\n",
    "    vid_id = vid.split(\".\")[0]\n",
    "    if vid.startswith(\".\") or os.path.exists(os.path.join(out_iclus_data,\"cam_\"+vid_id+\".npy\")):\n",
    "        print(\"already done\", vid)\n",
    "        continue\n",
    "    print(\"process next file \", vid)\n",
    "    preds = evaluator(os.path.join(iclus_dir, vid))\n",
    "    np.save(os.path.join(out_iclus_data,\"cam_\"+vid_id+\".npy\"), preds)\n",
    "    plt.imshow(evaluator.image_arr[0])\n",
    "    plt.savefig(os.path.join(out_iclus_data,\"cam_\"+vid_id+\"expl_img.png\"))\n",
    "    print(\"saved predictions\")\n",
    "    pred_plot(preds, os.path.join(out_iclus_data,\"cam_\"+vid_id))\n",
    "    print(\"saved plot\")\n",
    "    evaluator.cam_important_frames(GT_CLASS, save_video_path=os.path.join(out_iclus_data, \"cam_\"+vid_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICLUS notes:\n",
    "\n",
    "47 falsch predicted aber passt\n",
    "schaut weird aus: 48, 49, 50 (linear or what is this? alle als healthy predicted)\n",
    "Must do again: 36\n",
    "\n",
    "13, 11, 31, 32: linear probes that are deleted, 22, 24, 26 (they are all kept), 28\n",
    "\n",
    "12, 15, 16, 17, 18, 19, 20 were fine already with bad cropping\n",
    "1, 3, 9, 10 is fine already\n",
    "\n",
    "NEW PROCESSED: 14, 8, 7, 6, 4, 5, 2\n",
    "\n",
    "CODE TO PROCESS SOME AGAIN:\n",
    "if os.path.exists(\"vids_preds_iclus/cam_vid\"+vid_id+\".npy\"):\n",
    "    preds_prev = np.load(\"vids_preds_iclus/cam_vid\"+vid_id+\".npy\")\n",
    "    predicted_class = np.argmax(np.mean(np.array(preds_prev), axis=0))\n",
    "    print(predicted_class, np.mean(np.array(preds_prev), axis=0))\n",
    "    if predicted_class==0:\n",
    "        print(\"file is already predicted covid\", vid)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_in_path = \"../../data/pocus_videos/Convex/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_dict = {\"Cov\":0, \"Reg\":2, \"Pne\":1, \"pne\":1}\n",
    "out_path=\"vid_outputs_cam\"\n",
    "for vid in os.listdir(vid_in_path):\n",
    "    if vid[:3] not in [\"Pne\", \"pne\", \"Cov\", \"Reg\"]:\n",
    "        print(vid)\n",
    "        continue\n",
    "    if os.path.exists(os.path.join(out_path, vid.split(\".\")[0]+\".mpeg\")):\n",
    "        print(\"already done\", vid)\n",
    "        continue\n",
    "    vid_in = os.path.join(vid_in_path, vid)\n",
    "    print(vid_in)\n",
    "    preds = evaluator(vid_in)\n",
    "    gt = gt_dict[vid[:3]]\n",
    "    evaluator.cam_important_frames(gt, save_video_path=os.path.join(out_path, vid.split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_path_overall=\"vid_outputs_cam_test/\"\n",
    "path_crossval = \"../../data/cross_validation\"\n",
    "per_split = [[] for _ in range(5)]\n",
    "for fold in range(5):\n",
    "    out_path = os.path.join(out_path_overall, \"fold\"+str(fold))\n",
    "    # load weights of the respective fold model\n",
    "    print(\"NEW FOLD\", fold)\n",
    "    # make sure the variable is cleared\n",
    "    evaluator = None\n",
    "    # load weights\n",
    "    evaluator = VideoEvaluator(ensemble=False, split=fold, model_id=\"vgg_cam\", num_classes=4)\n",
    "    # get all names belonging to this fold\n",
    "    vidnames = []\n",
    "    for mod in [\"covid\", \"pneumonia\", \"regular\"]:\n",
    "        for f in os.listdir(os.path.join(path_crossval, \"split\"+str(fold), mod)):\n",
    "            if f[0]!=\".\":\n",
    "                fparts = f.split(\".\")\n",
    "                vidnames.append(fparts[0]+\".\"+fparts[1][:3])\n",
    "    # iterate over the relevant files\n",
    "    names = np.unique(vidnames)\n",
    "    for name in names:\n",
    "        if name[-3:] in [\"mp4\", \"mov\", \"gif\"]:\n",
    "            print(name)\n",
    "            vid_in = os.path.join(vid_in_path, name)\n",
    "            if not os.path.exists(vid_in):\n",
    "                print(\"does not exist! - butterfly?\", vid_in)\n",
    "                continue\n",
    "            if os.path.exists(os.path.join(out_path, name.split(\".\")[0]+\".mpeg\")):\n",
    "                print(\"already done\", name)\n",
    "                continue\n",
    "            print(vid_in)\n",
    "            preds = evaluator(vid_in)\n",
    "            gt = gt_dict[name[:3]]\n",
    "            evaluator.cam_important_frames(gt, save_video_path=os.path.join(out_path, name.split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make point plot for CAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_kernel(heatmap, kernel_size=9):\n",
    "    k2 = kernel_size//2\n",
    "    # pad array\n",
    "    arr = np.pad(heatmap, ((k2,k2),(k2,k2)), 'constant', constant_values=0)\n",
    "    # get coordinates of maximum\n",
    "    x_coords, y_coords = divmod(np.argmax(arr.flatten()), len(arr[0]))   \n",
    "    patch = arr[x_coords-k2:x_coords+k2+1, y_coords-k2:y_coords+k2+1]\n",
    "    # print(x_coords, y_coords)\n",
    "    # plt.imshow(arr)\n",
    "    # plt.show()\n",
    "    res_out = np.zeros((kernel_size-2,kernel_size-2))\n",
    "    for i in range(kernel_size-2):\n",
    "        for j in range(kernel_size-2):\n",
    "            res_out[i,j] = np.mean(patch[i:i+3, j:j+3])\n",
    "    max_x, max_y = divmod(np.argmax(res_out.flatten()), kernel_size-2)\n",
    "    # print(max_x, max_y)\n",
    "    # print(x_coords+max_x-k2+1, y_coords+max_y-k2+1)\n",
    "    # plt.imshow(res_out)\n",
    "    # plt.show()\n",
    "    return x_coords+max_x-2*k2+1, y_coords+max_y-2*k2+1\n",
    "# max_kernel((np.random.rand(10,10)*20).astype(int))\n",
    "\n",
    "def convolve_faster(img, kernel):\n",
    "    \"\"\"\n",
    "    Convolve a 2d img with a kernel, storing the output in the cell\n",
    "    corresponding the the left or right upper corner\n",
    "    :param img: 2d numpy array\n",
    "    :param kernel: kernel (must have equal size and width)\n",
    "    :param neg: if neg=0, store in upper left corner, if neg=1,\n",
    "    store in upper right corner\n",
    "    :return convolved image of same size\n",
    "    \"\"\"\n",
    "    k_size = len(kernel)\n",
    "    # a = np.pad(img, ((0, k_size-1), (0, k_size-1)))\n",
    "    padded = np.pad(img, ((k_size//2, k_size//2), (k_size//2, k_size//2)))\n",
    "\n",
    "    s = kernel.shape + tuple(np.subtract(padded.shape, kernel.shape) + 1)\n",
    "    strd = np.lib.stride_tricks.as_strided\n",
    "    subM = strd(padded, shape=s, strides=padded.strides * 2)\n",
    "    return np.einsum('ij,ijkl->kl', kernel, subM)\n",
    "\n",
    "# in_img = np.random.rand(20,20)\n",
    "# plt.imshow(in_img)\n",
    "# plt.show()\n",
    "# out = convolve_faster(in_img, np.ones((7,7)))\n",
    "# plt.imshow(out)\n",
    "# plt.show()\n",
    "# print(in_img.shape, out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_crossval = \"../../data/cross_validation\"\n",
    "gt_dict = {\"Reg\":2, \"Pne\":1, \"pne\":1, \"Cov\":0}\n",
    "\n",
    "gradcam = GradCAM()\n",
    "\n",
    "all_predictions = []\n",
    "heatmap_points, predicted, gt_class, overlays, fnames = [], [], [], [], []\n",
    "\n",
    "for fold in range(5):\n",
    "    # load weights of the respective fold model\n",
    "    print(\"NEW FOLD\", fold)\n",
    "    # make sure the variable is cleared\n",
    "    evaluator = None\n",
    "    # load weights\n",
    "    evaluator = Evaluator(ensemble=False, split=fold, model_id=\"vgg_base\", num_classes=4)\n",
    "    # get all names belonging to this fold\n",
    "    all_images_arr = []\n",
    "    gt, name = [], []\n",
    "    for mod in [\"covid\", \"pneumonia\", \"regular\"]:\n",
    "        for f in os.listdir(os.path.join(path_crossval, \"split\"+str(fold), mod)):\n",
    "            if f[0]!=\".\":\n",
    "                # fparts = f.split(\".\")\n",
    "                # vidnames.append(fparts[0]+\".\"+fparts[1][:3])\n",
    "                img_loaded = cv2.imread(os.path.join(path_crossval, \"split\"+str(fold), mod, f))\n",
    "                img_preprocc = evaluator.preprocess(img_loaded)[0]\n",
    "                gt.append(gt_dict[f[:3]])\n",
    "                all_images_arr.append(img_preprocc)\n",
    "                name.append(f)\n",
    "    all_images_arr = np.array(all_images_arr)\n",
    "    # get predictions\n",
    "    print(\"process all images in fold\", fold, \"with shape\", all_images_arr.shape)\n",
    "    fold_preds = evaluator.models[0].predict(all_images_arr)\n",
    "    class_idx_per_img = np.argmax(fold_preds, axis=1)\n",
    "    all_predictions.append(fold_preds)\n",
    "    \n",
    "    # get heatmap \n",
    "    for i, img in enumerate(all_images_arr):\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "        # overlay, heatmap = get_class_activation_map(evaluator.models[0], img, gt[i], image_weight=1, return_map=True, zeroing=0.65)\n",
    "        overlay, heatmap = gradcam.explain(img, evaluator.models[0], gt[i], return_map=True, image_weight=1, layer_name=\"block5_conv3\", zeroing=0.65, heatmap_weight=0.25)     \n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # plt.imshow(overlay.astype(int))\n",
    "        # plt.show()\n",
    "        overlays.append(overlay.astype(int))\n",
    "        # convolve with big kernel\n",
    "        convolved_overlay = convolve_faster(heatmap, np.ones((19,19)))\n",
    "        # print(\"previously:\", divmod(np.argmax(heatmap.flatten()), len(heatmap[0])))\n",
    "        x_coord, y_coord = divmod(np.argmax(convolved_overlay.flatten()), len(convolved_overlay[0]))\n",
    "        ## previous version: 9x9 umkreis and 3x3 kernel\n",
    "        # x_coord, y_coord = max_kernel(heatmap) # np.where(heatmap==np.max(heatmap))\n",
    "        # print(x_coord, y_coord)\n",
    "        heatmap_points.append([x_coord, y_coord])\n",
    "        predicted.append(class_idx_per_img[i])\n",
    "        gt_class.append(gt[i])\n",
    "        fnames.append(name[i])\n",
    "        # print([x_coord, y_coord], class_idx_per_img[i], gt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted), len(gt_class), len(heatmap_points), np.asarray(overlays).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.asarray(predicted)==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_p = np.array(heatmap_points)\n",
    "print(hm_p.shape)\n",
    "# plt.figure(figsize=(20,20))\n",
    "plt.imshow(overlays[1])\n",
    "plt.scatter(hm_p[:,1], hm_p[:,0], c=predicted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hm_p = np.array(heatmap_points)\n",
    "print(hm_p.shape)\n",
    "# plt.figure(figsize=(20,20))\n",
    "plt.imshow(overlays[1])\n",
    "plt.scatter(hm_p[:,1], hm_p[:,0], c=predicted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"file\"] = fnames\n",
    "df[\"predicted\"] = predicted\n",
    "df[\"gt\"] = gt_class\n",
    "df[\"max_x\"] = np.asarray(heatmap_points)[:,0].tolist()\n",
    "df[\"max_y\"] = np.asarray(heatmap_points)[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"heatmap_points_grad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"overlayed_hm.npy\", overlays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICLUS evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_iclus_data = \"vids_preds_regular_test\"\n",
    "out_iclus_data = \"vids_preds_iclus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_preds = []\n",
    "correct_frames = 0\n",
    "wrong_frames = 0\n",
    "avg_corr_frames = []\n",
    "all_frames = 0\n",
    "# plt.figure(figsize=(20,10))\n",
    "for f in os.listdir(out_iclus_data):\n",
    "    if f[-3:]==\"npy\":\n",
    "        preds = np.load(os.path.join(out_iclus_data, f))\n",
    "        # plt.plot(preds[:,0])\n",
    "        # print(preds.shape)\n",
    "        # frame based\n",
    "        frame_pred = np.argmax(preds, axis=1)\n",
    "        all_frames += len(frame_pred)\n",
    "        correct_frames += np.sum(frame_pred==0)\n",
    "        wrong_frames += np.sum(frame_pred!=0)\n",
    "        avg_corr_frames.append(np.sum(frame_pred==0)/len(frame_pred))\n",
    "        # video classification - majority vote\n",
    "        uni, counts = np.unique(frame_pred, return_counts=True)\n",
    "        # all_class_preds.append(uni[np.argmax(counts)])\n",
    "        # version with probabilities and not majority vote:\n",
    "        vid_class_pred = np.argmax(np.mean(preds, axis=0))\n",
    "        all_class_preds.append(vid_class_pred)\n",
    "        if all_class_preds[-1]!=0:\n",
    "            print(\"wrongly classified\", f)\n",
    "        \n",
    "# print(wrong_frames+ correct_frames, all_frames)\n",
    "print(\"Included in total ICLUS videos (without linear probes):\", len(all_class_preds))\n",
    "assert all_frames==wrong_frames+correct_frames\n",
    "print(\"Frame accuracy:\", correct_frames/float(all_frames))\n",
    "print(\"video class accuracy (max avg probability): \", np.sum(np.array(all_class_preds)==0)/len(all_class_preds))\n",
    "print(\"Mean and std of ratio of correctly classified frames per video:\", np.mean(avg_corr_frames), np.std(avg_corr_frames))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclus_preds = all_class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Lotte's test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_test_data = \"vid_outputs_REGULAR\"\n",
    "all_class_preds = []\n",
    "correct_frames = 0\n",
    "wrong_frames = 0\n",
    "avg_corr_frames = []\n",
    "all_frames = 0\n",
    "# plt.figure(figsize=(20,10))\n",
    "for subdir in os.listdir(reg_test_data):\n",
    "    if subdir[0]==\".\":\n",
    "        continue\n",
    "    print(subdir)\n",
    "    for f in os.listdir(os.path.join(reg_test_data, subdir)):\n",
    "        if f[-3:]==\"npy\":\n",
    "            preds = np.load(os.path.join(reg_test_data, subdir, f))\n",
    "            print(os.path.join(reg_test_data, subdir, f))\n",
    "            # print(preds.shape)\n",
    "            # frame based\n",
    "            frame_pred = np.argmax(preds, axis=1)\n",
    "            all_frames += len(frame_pred)\n",
    "            correct_frames += np.sum(frame_pred==2)\n",
    "            wrong_frames += np.sum(frame_pred!=2)\n",
    "            avg_corr_frames.append(np.sum(frame_pred==2)/len(frame_pred))\n",
    "            # video classification - majority vote\n",
    "            \n",
    "            vid_class_pred = np.argmax(np.mean(preds, axis=0))\n",
    "            all_class_preds.append(vid_class_pred)\n",
    "            # print(frame_pred)\n",
    "            if all_class_preds[-1]!=2:\n",
    "                print(\"wrongly classified\", f)\n",
    "            # version with probabilities and not majority vote:\n",
    "            # vid_class_pred = np.argmax(np.mean(preds, axis=0))\n",
    "            # all_class_preds.append(vid_class_pred)\n",
    "# print(wrong_frames+ correct_frames, all_frames)\n",
    "print(\"Included in total ICLUS videos (without linear probes):\", len(all_class_preds))\n",
    "assert all_frames==wrong_frames+correct_frames\n",
    "print(\"Frame accuracy:\", correct_frames/float(all_frames))\n",
    "print(\"video class accuracy (max avg probability): \", np.sum(np.array(all_class_preds)==2)/len(all_class_preds))\n",
    "print(\"Mean and std of ratio of correctly classified frames per video:\", np.mean(avg_corr_frames), np.std(avg_corr_frames))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_preds = all_class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity of both together\n",
    "all_gt = np.asarray([1 for _ in range(len(iclus_preds))] + [0 for _ in range(len(reg_preds))])\n",
    "all_preds = np.asarray(iclus_preds + reg_preds)\n",
    "all_preds = np.absolute(all_preds/2 - 1).astype(int)\n",
    "print(all_preds)\n",
    "print(len(all_preds), len(all_gt))\n",
    "print(recall_score(all_gt, all_preds))\n",
    "print(precision_score(all_gt, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(all_gt, all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD comments evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(\"mapping.csv\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_comments = pd.read_csv(\"CAM_scores_GB.csv\")\n",
    "gb_comments = gb_comments.drop([0,1])\n",
    "lotte_comments = pd.read_csv(\"CAM_scores_lotte.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotte_comments = lotte_comments.rename(columns={'Score - how helpful is the heatmap (0=only distracting, 5=very helpful)': 'lotte_score', \n",
    "                                                'Better one (put 1 if this one is the better one)': \"lotte_better\",\n",
    "                                               'Class (Your guess)': 'lotte_class',\n",
    "                                               'Patterns that can be seen':'lotte_patterns',\n",
    "                                               'Patterns the heatmap highlights':'lotte_heatmap_patterns'}).drop(columns=[\"Unnamed: 6\"])\n",
    "gb_comments = gb_comments.rename(columns={'Score - how helpful is the heatmap (0=only distracting, 5=very helpful)': 'gb_score', \n",
    "                                                'Better one (put 1 if this one is the better one)': \"gb_better\",\n",
    "                                               'Class (Your guess)': 'gb_class',\n",
    "                                               'Patterns that can be seen':'gb_patterns',\n",
    "                                               'Patterns the heatmap highlights':'gb_heatmap_patterns'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotte_comments['lotte_score'] = lotte_comments['lotte_score'].apply(lambda x: x-3 + int(x>=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_map_gb = pd.merge(mapping, gb_comments, how=\"inner\", left_on=\"new_filename\", right_on=\"Filename\")\n",
    "merge_map_lotte = pd.merge(merge_map_gb, lotte_comments, how=\"inner\", left_on=\"new_filename\", right_on=\"Filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_map_lotte.to_csv(\"CAM_scores_MDs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after manual cleaning:\n",
    "final_table = pd.read_csv(\"CAM_scores_MDs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_gb = 0\n",
    "test_score_gb = 0\n",
    "train_score_lo = 0\n",
    "test_score_lo = 0\n",
    "train_better_gb = []\n",
    "train_better_lo = []\n",
    "for group_name, group_df in final_table.groupby(\"previous_filename\"):\n",
    "    print(\"--------\")\n",
    "    print(group_df[[\"gb_better\", \"lotte_better\", \"is_train\"]])\n",
    "    if np.all(pd.isnull(group_df[\"gb_better\"])) or len(np.where(group_df[\"gb_better\"].values==\"1\")[0])==0:\n",
    "        train_score_gb += 0.5\n",
    "        test_score_gb += 0.5\n",
    "        print(\"gb: equally good\")\n",
    "        train_better_gb.append(0.5)\n",
    "    else:\n",
    "        # if len(np.where(group_df[\"gb_better\"].values==\"1\")[0])==0:\n",
    "        #     raise RuntimeError(\"no valid value found\")\n",
    "        if np.where(group_df[\"gb_better\"].values==\"1\")==np.where(group_df[\"is_train\"].values==1):\n",
    "            print(\"gb: train better\")\n",
    "            train_score_gb += 1\n",
    "            train_better_gb.append(1)\n",
    "        else:\n",
    "            test_score_gb += 1\n",
    "            train_better_gb.append(0)\n",
    "            print(\"gb: test better\")\n",
    "    # get lotte score\n",
    "    if np.all(pd.isnull(group_df[\"lotte_better\"])):\n",
    "        train_score_gb += 0.5\n",
    "        test_score_gb += 0.5\n",
    "        train_better_lo.append(0.5)\n",
    "        print(\"lotte: equally good\")\n",
    "    else:\n",
    "        if len(np.where(group_df[\"lotte_better\"].values==1)[0])==0:\n",
    "            raise RuntimeError(\"no valid value found\")\n",
    "        if np.where(group_df[\"lotte_better\"].values==1)==np.where(group_df[\"is_train\"].values==1):\n",
    "            print(\"lotte: train better\")\n",
    "            train_score_lo += 1\n",
    "            train_better_lo.append(1)\n",
    "        else:\n",
    "            test_score_lo += 1\n",
    "            train_better_lo.append(0)\n",
    "            print(\"lotte: test better\")\n",
    "    \n",
    "    for i, row in group_df.iterrows():\n",
    "        if int(row[\"is_train\"])==1:\n",
    "            print(row[\"gb_better\"], row[\"lotte_better\"], row[\"is_train\"])\n",
    "    # gb_scores = group_df[\"gb_better\"]\n",
    "    # lotte_scores = group_df[\"lotte_better\"]\n",
    "    # train_test = group_df[\"is_train\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_better_lo), len(train_better_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_arr = np.swapaxes(np.stack([train_better_lo, train_better_gb]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree = np.sum(better_arr[:,0]==better_arr[:,1])\n",
    "print(\"agreement (both exactly same)\", agree/len(better_arr))\n",
    "print(\"disagreement (one 1 one 0)\", len(np.where(np.absolute(better_arr[:,0]-better_arr[:,1])==1)[0])/len(better_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average score for train better:\", np.mean(train_better_lo), np.mean(train_better_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numbers unique\",np.unique(train_better_lo, return_counts=True), np.unique(train_better_gb, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate scores - Add label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [val[:3].lower() for val in final_table[\"previous_filename\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_table[final_table[\"is_train\"]==0][\"gb_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table[\"label\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get average score of Lotte and Gabriel together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_test = final_table[final_table[\"is_train\"]==0]\n",
    "all_scores = only_test[\"gb_score\"].values.tolist() + only_test[\"lotte_score\"].values.tolist()\n",
    "print(\"Mean score lotte and gabriel together (test):\", np.mean(all_scores))\n",
    "# other method: average per video scores first:\n",
    "mean_scores = 0.5* (only_test[\"gb_score\"].values + only_test[\"lotte_score\"].values)\n",
    "print(\"Mean score lotte and gabriel together (test) - other method:\", np.mean(mean_scores))\n",
    "print(np.vstack([only_test[\"gb_score\"].values, only_test[\"lotte_score\"].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_test[\"mean_scores\"] = mean_scores.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_test.groupby(\"label\").agg({\"mean_scores\":\"mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test whether test better train significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, wilcoxon, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_train = final_table[final_table[\"is_train\"]==1]\n",
    "all_train_scores = only_train[\"gb_score\"].values.tolist() + only_train[\"lotte_score\"].values.tolist()\n",
    "only_test = final_table[final_table[\"is_train\"]==0]\n",
    "all_test_scores = only_test[\"gb_score\"].values.tolist() + only_test[\"lotte_score\"].values.tolist()\n",
    "print(\"means\", np.mean(all_train_scores), np.mean(all_test_scores))\n",
    "\n",
    "print(\"Ttest ind:\", ttest_ind(all_train_scores,all_test_scores, equal_var=False))\n",
    "print(\"ttest related:\", ttest_rel(all_train_scores,all_test_scores))\n",
    "print(\"Wilcoxon:\", wilcoxon(all_train_scores,all_test_scores))\n",
    "print(\"mannwhitneyu\", mannwhitneyu(all_train_scores,all_test_scores))\n",
    "# Ttest related\n",
    "# Examples for use are scores of the same set of student in different exams, \n",
    "# or repeated sampling from the same units. The test measures whether the average score\n",
    "# differs significantly across samples (e.g. exams). If we observe a large p-value, for\n",
    "# example greater than 0.05 or 0.1 then we cannot reject the null hypothesis of identical average scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_train_scores), len(all_test_scores))\n",
    "plt.scatter(range(len(all_test_scores)), all_test_scores)\n",
    "plt.scatter(range(len(all_train_scores)), all_train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouped for separate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "only_test = final_table[final_table[\"is_train\"]==0]\n",
    "grouped = only_test.groupby(\"label\").agg({\"lotte_score\":\"mean\", \"gb_score\":\"mean\"})\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_test = only_test.fillna(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_all_with_consolidations = only_test[only_test[\"gb_patterns\"].str.contains(\"onsolida\")]\n",
    "print(\"number of videos with consolidations\", len(gb_all_with_consolidations))\n",
    "print(\"GB heatmap highlights consolidation\", len(gb_all_with_consolidations[gb_all_with_consolidations[\"gb_heatmap_patterns\"].str.contains(\"onsolida\")]))\n",
    "print(\"Lotte heatmap highlights consolidation\", len(gb_all_with_consolidations[gb_all_with_consolidations[\"lotte_heatmap_patterns\"].str.contains(\"onsolida\")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_all_with_alines = only_test[only_test[\"gb_patterns\"].str.contains(\"A\")]\n",
    "print(\"number of videos with A lines\", len(gb_all_with_alines))\n",
    "print(\"GB heatmap highlights A lines\", len(gb_all_with_alines[gb_all_with_alines[\"gb_heatmap_patterns\"].str.contains(\"A\")]))\n",
    "print(\"Lotte heatmap highlights A lines\", len(gb_all_with_alines[gb_all_with_alines[\"lotte_heatmap_patterns\"].str.contains(\"A\")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_all_with_blines = only_test[only_test[\"gb_patterns\"].str.contains(\"B\")]\n",
    "print(\"number of videos with B lines\", len(gb_all_with_blines))\n",
    "print(\"GB heatmap highlights B lines\", len(gb_all_with_blines[gb_all_with_blines[\"gb_heatmap_patterns\"].str.contains(\"B\")]))\n",
    "print(\"Lotte heatmap highlights B lines\", len(gb_all_with_blines[gb_all_with_blines[\"lotte_heatmap_patterns\"].str.contains(\"B\")]))\n",
    "print(\"Note: Lotte usually writes that it catches ONE bline in the video, or beginning of bline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wise = []\n",
    "for pattern in [\"onsol\", \"B\", \"A\"]:\n",
    "    print(\"--------\", pattern)\n",
    "    gb_all_with_pattern = only_test[only_test[\"gb_patterns\"].str.contains(pattern)]\n",
    "    for classe in [\"cov\", \"pne\", \"reg\"]:\n",
    "        class_filtered = gb_all_with_pattern[gb_all_with_pattern[\"label\"]==classe]\n",
    "        print(classe, pattern, len(class_filtered))\n",
    "        # gb_all_with_pattern = class_filtered[class_filtered[\"gb_patterns\"].str.contains(pattern)]\n",
    "        number_found = 0.5*(len(class_filtered[class_filtered[\"gb_heatmap_patterns\"].str.contains(pattern)])\n",
    "        + len(class_filtered[class_filtered[\"lotte_heatmap_patterns\"].str.contains(pattern)]))\n",
    "        if len(class_filtered)>0:\n",
    "            print(classe, number_found/len(class_filtered))\n",
    "        \n",
    "# print(gb_all_with_pattern[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rects = ax.barh([\"Consolidations \\n (pneumonia)\", \"A-lines \\n (healthy)\", \"Pleural line \\n (healthy if regular)\", \"B-lines \\n (COVID-19)\"], [17/18, 8/13, 9/20, 3/12], width\n",
    "        , color = [\"palegreen\",\"greenyellow\",\"sandybrown\", \"indianred\"])\n",
    "ax.set_xlim(0,1)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "# ax.set_ylabel('Scores')\n",
    "# ax.set_title('Scores by group and gender')\n",
    "# ax.set_yticks([\"Consolidations \\n (pneumonia)\", \"A-lines \\n (healthy)\", \"Pleural line \\n (healthy if regular)\", \"B-lines \\n (COVID-19)\"], fontsize=13)\n",
    "ax.set_xlabel(\"Ratio of samples highlighted by CAM\", fontsize=13)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "autolabel(rects)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "width=0.5\n",
    "plt.barh([\"Consolidations \\n (pneumonia)\", \"A-lines \\n (healthy)\", \"Pleural line\", \"B-lines \\n (COVID-19)\"], [17/18, 8/13, 9/20, 3/12], width\n",
    "        , color = [\"palegreen\",\"greenyellow\",\"sandybrown\", \"indianred\"])\n",
    "plt.xlim(0,1)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xlabel(\"Ratio of samples highlighted by CAM\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"barplot_cam.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FROM GABRIELS PATTERNS:\")\n",
    "for pattern in [\"onsolida\", \"A\", \"B\", \"ronchogram\", \"ffusion\"]:\n",
    "    print(\"-------------------\")\n",
    "    gb_all_with_pattern = only_test[only_test[\"gb_patterns\"].str.contains(pattern)]\n",
    "    print(\"number of videos with \", pattern, len(gb_all_with_pattern))\n",
    "    print(\"GB heatmap highlights \", pattern, len(gb_all_with_pattern[gb_all_with_pattern[\"gb_heatmap_patterns\"].str.contains(pattern)]))\n",
    "    print(\"Lotte heatmap highlights \", pattern, len(gb_all_with_pattern[gb_all_with_pattern[\"lotte_heatmap_patterns\"].str.contains(pattern)]))\n",
    "print(\"---------------\")\n",
    "print(\"Note: observed that both MDs agreed where consolidations are found\")\n",
    "print(\"Note: Lotte usually writes that it catches ONE bline in the video, or beginning of bline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"FROM LOTTES PATTERNS:\")\n",
    "for pattern in [\"onsolida\", \"A\", \"B\", \"ffusion\", \"leura\"]:\n",
    "    print(\"-------------------\")\n",
    "    gb_all_with_pattern = only_test[only_test[\"lotte_patterns\"].str.contains(pattern)]\n",
    "    print(\"number of videos with \", pattern, len(gb_all_with_pattern))\n",
    "    print(\"GB heatmap highlights \", pattern, len(gb_all_with_pattern[gb_all_with_pattern[\"gb_heatmap_patterns\"].str.contains(pattern)]))\n",
    "    print(\"Lotte heatmap highlights \", pattern, len(gb_all_with_pattern[gb_all_with_pattern[\"lotte_heatmap_patterns\"].str.contains(pattern)]))\n",
    "print(\"---------------\")\n",
    "print(\"Note: observed that both MDs agreed where consolidations are found\")\n",
    "print(\"Note: Lotte usually writes that it catches ONE bline in the video, or beginning of bline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"overall number of videos\", len(only_test))\n",
    "for name in [\"gb\", \"lotte\"]:\n",
    "    print(\"---------- \"+name+\" --------------\")\n",
    "    for pattern in [\"uscle\", \"fat\", \"skin\"]:\n",
    "        print(pattern, np.sum(only_test[name+\"_heatmap_patterns\"].str.contains(pattern)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "GB: 1 time \"Avoids the liver, I'm impressed, but several times \"tricked by the liver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normal_eval = Evaluator(ensemble=False, split=0) # , model_id=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_in = vid_in_path + \"Pneu_liftl_pneu_case3_clip5.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../../data/my_found_data/Cov_efsumb1_2.png\")\n",
    "img = cv2.imread(\"../../data/pocus_images/convex/Cov_blines_covidmanifestation_paper2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = evaluator.preprocess(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = GradCAM()\n",
    "out_map = grad.explain(img[0], evaluator.models[0], 0, return_map=False, layer_name=\"block5_conv3\", zeroing=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out_map.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cam = get_class_activation_map(evaluator.models[0], img, 1, heatmap_weight=0.1, zeroing=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = \"../../data/cross_validation\"\n",
    "file_list = []\n",
    "for folder in os.listdir(check):\n",
    "    if folder[0]==\".\":\n",
    "        continue\n",
    "    for classe in os.listdir(os.path.join(check, folder)):\n",
    "        if classe[0]==\".\": # or classe[0]==\"u\":\n",
    "            continue\n",
    "        uni = []\n",
    "        is_image = 0\n",
    "        for file in os.listdir(os.path.join(check, folder, classe)):\n",
    "            if file[0]==\".\":\n",
    "                continue\n",
    "            if len(file.split(\".\"))==2:\n",
    "                is_image+=1\n",
    "            file_list.append(file)\n",
    "            uni.append(file.split(\".\")[0])\n",
    "            # assert file[:3].lower()==classe[:3], \"wrong label\"+file[:3]+classe[:3]\n",
    "        print(folder, classe, len(np.unique(uni)), len(uni), is_image)\n",
    "assert len(file_list)==len(np.unique(file_list))\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy from train and test folders, give new ideas, and construct mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcam = \"vid_outputs_cam_test\"\n",
    "files_to_process = []\n",
    "for subdir in os.listdir(testcam):\n",
    "    if subdir[0]==\".\" or subdir==\"not taken\" :\n",
    "        continue\n",
    "    for f in os.listdir(os.path.join(testcam, subdir)):\n",
    "        if f[0]==\".\":\n",
    "            continue\n",
    "        \n",
    "        if not os.path.exists(os.path.join(\"vid_outputs_cam\", f)):\n",
    "            print(\"does not exist in train\", subdir, f)\n",
    "            # if not \"RUQ\" in f:\n",
    "             #   todo.append(f.split(\".\")[0])\n",
    "        else:\n",
    "            files_to_process.append(os.path.join(subdir, f))\n",
    "# print(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to copy files to randomized thing\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_cams_dir = \"vids_to_check\"\n",
    "test_cam_dir = \"vid_outputs_cam_test\"\n",
    "train_cam_dir = \"vid_outputs_cam\"\n",
    "# create directory\n",
    "if not os.path.exists(drop_cams_dir):\n",
    "    os.makedirs(drop_cams_dir)\n",
    "# give random ids\n",
    "ids = np.random.permutation(len(files_to_process))\n",
    "\n",
    "# define dataframe columns\n",
    "new_fname = []\n",
    "old_fname = []\n",
    "is_train = []\n",
    "fold = []\n",
    "for i, f_name_path in enumerate(files_to_process):\n",
    "    split_name, f_name = tuple(f_name_path.split(os.sep))\n",
    "    split = int(split_name[-1])\n",
    "    # randomly add to model2\n",
    "    out_f_name = \"video_\"+str(ids[i])+\"_model_\"\n",
    "    old_fname.append(f_name)\n",
    "    old_fname.append(f_name)\n",
    "    rand_folder_train = np.random.rand()<0.5\n",
    "    print(\"train gets 1?\", rand_folder_train)\n",
    "    \n",
    "    # copy train data\n",
    "    train_outfname = out_f_name + str(int(rand_folder_train)) + \".mpeg\"\n",
    "    train_to_path = os.path.join(drop_cams_dir, train_outfname)\n",
    "    cp_from_path = os.path.join(train_cam_dir, f_name)\n",
    "    # append for df\n",
    "    is_train.append(1)\n",
    "    fold.append(split)\n",
    "    new_fname.append(train_outfname)\n",
    "    print(\"TRAIN:\", cp_from_path, train_to_path)\n",
    "    shutil.copy(cp_from_path, train_to_path)\n",
    "    \n",
    "    # copy test \n",
    "    test_outfname = out_f_name + str(int(not rand_folder_train)) + \".mpeg\"\n",
    "    test_to_path = os.path.join(drop_cams_dir, test_outfname)\n",
    "    cp_from_path = os.path.join(test_cam_dir, split_name, f_name)\n",
    "    # append for df\n",
    "    fold.append(split)\n",
    "    is_train.append(0)\n",
    "    new_fname.append(test_outfname)\n",
    "    print(\"TEST:\", cp_from_path, test_to_path)\n",
    "    shutil.copy(cp_from_path, test_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"previous_filename\"] = old_fname\n",
    "df[\"new_filename\"] = new_fname\n",
    "df[\"is_train\"] = is_train\n",
    "df[\"fold\"] = fold\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(drop_cams_dir+\"/mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclus_dir = \"test_data_regular/pat1\"\n",
    "# out_path = \"iclus_videos_processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMERATE = 3\n",
    "MAX_FRAMES = 30\n",
    "\n",
    "for fn in os.listdir(iclus_dir):\n",
    "    if fn[0]==\".\":\n",
    "        continue\n",
    "    cap = cv2.VideoCapture(os.path.join(iclus_dir, fn))\n",
    "    n_frames = cap.get(7)\n",
    "    frameRate = cap.get(5)\n",
    "    nr_selected = 0\n",
    "    every_x_image = int(frameRate / FRAMERATE)\n",
    "    while cap.isOpened() and nr_selected < MAX_FRAMES:\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        print(cap.get(1), cap.get(2), cap.get(3), cap.get(4), cap.get(5), cap.get(6), cap.get(7))\n",
    "        h, w, _ = frame.shape\n",
    "        # print(h,w)\n",
    "        plt.imshow(frame[30:400, 80:450])\n",
    "        plt.show()\n",
    "        # SAVE\n",
    "       # if ((frameId+1) % every_x_image == 0):\n",
    "       #     # storing the frames in a new folder named test_1\n",
    "       #     filename = out_path + fn + \"_frame%d.jpg\" % frameId\n",
    "       #     cv2.imwrite(filename, frame)\n",
    "       #     nr_selected += 1\n",
    "       #     print(frameId, nr_selected)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "check = \"../../data/cross_validation_segmented\"\n",
    "out = \"../../data/cross_validation_segmented_new\"\n",
    "for folder in os.listdir(check):\n",
    "    if folder[0]==\".\":\n",
    "        continue\n",
    "    os.makedirs(os.path.join(out, folder))\n",
    "    for classe in os.listdir(os.path.join(check, folder)):\n",
    "        os.makedirs(os.path.join(out, folder, classe))\n",
    "        if classe[0]==\".\": # or classe[0]==\"u\":\n",
    "            continue\n",
    "        for f in os.listdir(os.path.join(check, folder, classe)):\n",
    "            if f[-3:]==\"gif\":\n",
    "                shutil.copy(os.path.join(check, folder, classe, f), os.path.join(out, folder, classe, f[:-4]))\n",
    "            elif f[-3:] ==\"npz\":\n",
    "                shutil.copy(os.path.join(check, folder, classe, f), os.path.join(out, folder, classe, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut Lotte's videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"pat1Image_132943.mpeg\",\n",
    "\"pat1Image_133043.mpeg\",\n",
    "\"pat1Image_133138.mpeg\",\n",
    "\"pat1Image_133232.mpeg\",\n",
    "\"pat1Image_133327.mpeg\",\n",
    "\"pat1Image_133410.mpeg\",\n",
    "\"pat2Image_133824.mpeg\",\n",
    "\"pat2Image_133952.mpeg\",\n",
    "\"pat2Image_134138.mpeg\",\n",
    "\"pat2Image_134240.mpeg\",\n",
    "\"pat2Image_134348.mpeg\",\n",
    "\"pat2Image_134441.mpeg\",\n",
    "\"pat3Image_134711.mpeg\",\n",
    "\"pat3Image_134811.mpeg\",\n",
    "\"pat3Image_134904.mpeg\",\n",
    "\"pat3Image_135026.mpeg\",\n",
    "\"pat3Image_135128.mpeg\",\n",
    "\"pat3Image_135215.mpeg\",\n",
    "\"pat4Image_135904.mpeg\",\n",
    "\"pat4Image_140024.mpeg\",\n",
    "\"pat4Image_140238.mpeg\",\n",
    "\"pat4Image_140434.mpeg\",\n",
    "\"pat4Image_140606.mpeg\",\n",
    "\"pat4Image_140705.mpeg\"]\n",
    "copy_path = \"../../data/pocus_videos/convex/\"\n",
    "for f in file_list:\n",
    "    video_path = \"reg_propro/\"+f\n",
    "    # cap = cv2.VideoCapture(video_path)\n",
    "    # print(cap.get(7))\n",
    "    # cap.release()\n",
    "    print(\"Reg_\"+f)\n",
    "    shutil.copy(video_path, copy_path+\"Reg_\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"reg_propro/pat4\"\n",
    "in_dir =  \"test_data_regular/pat4\"\n",
    "for vid in os.listdir(in_dir):\n",
    "    if vid[0]==\".\":\n",
    "        continue\n",
    "    video_path = os.path.join(in_dir, vid)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    images = []\n",
    "    counter = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if counter<1:\n",
    "            plt.imshow(frame[30:400, 80:450]) # ICLUS: [70:570, 470:970]) # [25:350, 100:425]) # LOTTE:[30:400, 80:450]\n",
    "            plt.show()\n",
    "            counter += 1\n",
    "            continue\n",
    "        counter += 1\n",
    "        img_processed = frame[30:400, 80:450]\n",
    "        images.append(img_processed)\n",
    "    cap.release()\n",
    "    \n",
    "    images = np.asarray(images)\n",
    "    print(images.shape)\n",
    "    io.vwrite(out_dir+ vid.split(\".\")[0]+\".mpeg\", images, outputdict={\"-vcodec\":\"mpeg2video\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display logo on frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vid = \"../../data/pocus_videos/convex/Pneu-Atlas-pneumonia2.gif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(test_vid)\n",
    "ret, frame = cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = plt.imread(\"Logo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = cv2.resize(logo, (50,50), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
