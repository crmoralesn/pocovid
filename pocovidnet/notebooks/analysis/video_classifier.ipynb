{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold as skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = \"../../data/pocus_videos/convex\"\n",
    "class_short = [\"cov\", \"pne\", \"reg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_files = [v for v in os.listdir(vid_path) if v[:3].lower() in class_short]\n",
    "labels = [vid[:3].lower() for vid in vid_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files,test_files, train_labels, test_labels = train_test_split(vid_files, labels, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MY_FR = 5\n",
    "DATA_SIZE = 5\n",
    "\n",
    "data_3d = []\n",
    "labels_3d = []\n",
    "files_3d = []\n",
    "for train_vid, train_lab in zip(test_files, test_labels):\n",
    "    cap = cv2.VideoCapture(os.path.join(vid_path, train_vid))\n",
    "    fr = cap.get(5)\n",
    "    show_every = round(fr/MY_FR)\n",
    "    print(train_vid, fr, cap.get(7), \"available frames:\", cap.get(7)/show_every)\n",
    "    frames_available = cap.get(7)/show_every  \n",
    "    end_is_close = frames_available % DATA_SIZE >= 4\n",
    "    number_selected = int(end_is_close) + frames_available//DATA_SIZE\n",
    "    print(number_selected, cap.get(7), \"show every\", show_every)\n",
    "    current_data = []\n",
    "    # for frame_id in range(int(cap.get(7))):\n",
    "    while cap.isOpened():\n",
    "        frame_id = cap.get(1)\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        # plt.imshow(image)\n",
    "        # plt.show()\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "        if frame_id%show_every==0 or (end_is_close and frame_id==int(cap.get(7)-1)):\n",
    "            current_data.append(image)\n",
    "        if len(current_data)==DATA_SIZE:\n",
    "            data_3d.append(current_data)\n",
    "            labels_3d.append(train_lab)\n",
    "            files_3d.append(train_vid)\n",
    "            current_data = []\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(data_3d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../../data/vid_class_test.dat\", \"wb\") as outfile:\n",
    "    pickle.dump((data_3d, labels_3d, files_3d), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 fold - DO NOT USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_files = [v for v in os.listdir(vid_path) if v[:3].lower() in class_short]\n",
    "labels = [vid[:3].lower() for vid in vid_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(vid_files)\n",
    "y = np.array(labels)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "video_cross_val = {}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(\"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    train_test_dict = {}\n",
    "    train_test_dict[\"train\"] = (X_train.tolist(), y_train.tolist())\n",
    "    train_test_dict[\"test\"] = (X_test.tolist(), y_test.tolist())\n",
    "    video_cross_val[fold] = train_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [video_cross_val[i][\"test\"][0] for i in range(5)]\n",
    "a = [e for b in a for e in b ]\n",
    "assert len(a)==len(np.unique(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross val from cross-validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check = \"../../data/cross_validation\"\n",
    "videos_dir = \"../../data/pocus_videos/convex\"\n",
    "\n",
    "file_list = []\n",
    "video_cross_val = {}\n",
    "for split in range(5):\n",
    "    train_test_dict = {\"test\":[[],[]], \"train\":[[],[]]}\n",
    "    for folder in os.listdir(check):\n",
    "        if folder[0]==\".\":\n",
    "            continue\n",
    "        for classe in os.listdir(os.path.join(check, folder)):\n",
    "            if classe[0]==\".\" or classe[0]==\"u\":\n",
    "                continue\n",
    "            uni = []\n",
    "            for file in os.listdir(os.path.join(check, folder, classe)):\n",
    "                if file[0]==\".\" or len(file.split(\".\"))==2:\n",
    "                    continue\n",
    "                parts = file.split(\".\")\n",
    "                if not os.path.exists(os.path.join(videos_dir, parts[0]+\".\"+parts[1].split(\"_\")[0])):\n",
    "                    butterfly_name = parts[0][:3]+\"_Butterfly_\"+parts[0][4:]+\".avi\"\n",
    "                    if not os.path.exists(os.path.join(videos_dir,butterfly_name)):\n",
    "                        print(\"green dots in video or aibronch\", file)\n",
    "                        continue\n",
    "                    uni.append(butterfly_name)\n",
    "                else:\n",
    "                    uni.append(parts[0]+\".\"+parts[1].split(\"_\")[0])\n",
    "            uni_files_in_split = np.unique(uni)\n",
    "            uni_labels = [vid[:3].lower() for vid in uni_files_in_split]\n",
    "            \n",
    "            if folder[-1]==str(split):\n",
    "                train_test_dict[\"test\"][0].extend(uni_files_in_split)\n",
    "                train_test_dict[\"test\"][1].extend(uni_labels)\n",
    "            else:\n",
    "                train_test_dict[\"train\"][0].extend(uni_files_in_split)\n",
    "                train_test_dict[\"train\"][1].extend(uni_labels)\n",
    "    video_cross_val[split] = train_test_dict            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_class = {\"cov\": \"covid\", \"pne\": \"pneumonia\", \"reg\": \"regular\"}\n",
    "for i in range(5):\n",
    "    all_labels = []\n",
    "    files, labs = video_cross_val[i][\"test\"]\n",
    "    for j in range(len(files)):\n",
    "        if True: # \"Butterfly\" not in files[j]:\n",
    "            if not os.path.exists(\n",
    "                os.path.join(\n",
    "                    \"../../data/cross_validation/split\" + str(i),\n",
    "                    this_class[labs[j]], files[j] + \"_frame0.jpg\"\n",
    "                )\n",
    "            ):\n",
    "                print(files[j] + \"  in  \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(\"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    train_test_dict = {}\n",
    "    train_test_dict[\"train\"] = (X_train.tolist(), y_train.tolist())\n",
    "    train_test_dict[\"test\"] = (X_test.tolist(), y_test.tolist())\n",
    "    video_cross_val[fold] = train_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/cross_val_new.json\", \"w\") as outfile:\n",
    "    json.dump(video_cross_val, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for butterfly data to videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skvideo import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pocovidnet.utils_butterfly_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butterfly_dir = \"../../data/butterfly\"\n",
    "out_dir = \"../../data/butterfly_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_names, labels = get_paths(\"../../data/pocovid_data.csv\")\n",
    "# manually add the ones which I know are in the data\n",
    "files_to_process, labs_to_process = get_processing_info(\n",
    "    butterfly_dir, actual_names, labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del_upper = 100\n",
    "for i in range(1, len(files_to_process)):\n",
    "    vid_arr = []\n",
    "    fp = files_to_process[i]\n",
    "    fn = fp.split(os.sep)[-1]\n",
    "    cap = cv2.VideoCapture(fp)  # capturing the video from the given path\n",
    "    # frame rate\n",
    "    n_frames = cap.get(7)\n",
    "    frameRate = cap.get(5)\n",
    "    out_path = os.path.join(out_dir, label_to_dir(labs_to_process[i]).split(os.sep)[1][:3])\n",
    "    print(out_path)\n",
    "    print(\n",
    "        \"PROCESS\", fn, labs_to_process[i], \"framerate\", int(cap.get(5)),\n",
    "        \"width\", cap.get(3), \"height\", cap.get(4), \"number frames:\",\n",
    "        cap.get(7)\n",
    "    )\n",
    "    if os.path.exists(out_path+\"_\"+fn.split(\".\")[0]+\".mpeg\"):\n",
    "        print(\"already done, \", out_path+\"_\"+fn.split(\".\")[0]+\".mpeg\")\n",
    "        continue\n",
    "\n",
    "    nr_selected = 0\n",
    "    while cap.isOpened():\n",
    "        frameId = cap.get(1)  # current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = np.asarray(frame).astype(int)\n",
    "        # width_box = np.min(frame.shape[:2])\n",
    "        # crop\n",
    "        width_border = int(cap.get(3) * 0.15)\n",
    "        width_box = int(cap.get(3)) - 2 * width_border\n",
    "        if width_box + del_upper > cap.get(4):\n",
    "            width_box = int(cap.get(4)-del_upper)\n",
    "            width_border = int(cap.get(3)/2-width_box/2)\n",
    "        # print(del_upper, width_box, width_border)\n",
    "        frame = frame[del_upper:width_box +\n",
    "                      del_upper, width_border:width_box + width_border]\n",
    "        \n",
    "        # print(frame.shape)\n",
    "        # frame = frame[width_border:width_box+width_border]\n",
    "        # detect green point\n",
    "        green_point = frame[:, :, 1] - frame[:, :, 0]\n",
    "        # get first frame for green point deletion:\n",
    "        if frameId == 0:\n",
    "            frame_start = green_point\n",
    "        # skip the green moving points\n",
    "        if np.any((green_point - frame_start) > 100):\n",
    "            plt.imshow(green_point)\n",
    "            plt.show()\n",
    "            print(\"VID WITH GREEN DOT\")\n",
    "            break\n",
    "        # delete blue symbol\n",
    "        blue_symbol = np.where(green_point < -50)\n",
    "        frame[blue_symbol] = frame[0, 0]\n",
    "        # delete green symbol\n",
    "        if np.any(green_point > 220):\n",
    "            green_symbol = np.where(green_point > 50)\n",
    "            frame[green_symbol] = frame[0, 0]\n",
    "        # resize\n",
    "        # print(frame.shape)\n",
    "        frame = np.asarray(frame).astype(np.uint8)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (240, 240))\n",
    "        if frameId==0:\n",
    "            plt.imshow(frame)\n",
    "            plt.show()\n",
    "        vid_arr.append(frame)\n",
    "        # SAVE\n",
    "        # if (frameId % every_x_image == 0):\n",
    "        #     # storing the frames in a new folder named test_1\n",
    "        #     filename = out_path + fn + \"_frame%d.jpg\" % frameId\n",
    "        #     cv2.imwrite(filename, frame)\n",
    "        #     nr_selected += 1\n",
    "    cap.release()\n",
    "    vid_arr = np.asarray(vid_arr)\n",
    "    # print(out_path, fp, fn)\n",
    "    if len(vid_arr)>5:\n",
    "        io.vwrite(out_path+\"_Butterfly_\"+fn.split(\".\")[0]+\".mpeg\", vid_arr, outputdict={\"-vcodec\":\"mpeg2video\"})\n",
    "        print(\"DONE\", vid_arr.shape)\n",
    "    else:\n",
    "        print(\"GREEN DOT:\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/ninawiedemann/Desktop/Projects/covid19_pocus_ultrasound.nosync/data/video_input_data/conv3d_train_fold_1.dat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    data_path, \"rb\"\n",
    ") as infile:\n",
    "    X_train, train_labels_text, train_files = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels_text, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, vid in enumerate(X_train):\n",
    "    print(train_files[i])\n",
    "    plt.imshow(vid[0, :, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out framerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for vid in os.listdir(\"../../data/pocus_videos/convex\"):\n",
    "    if vid[0]==\".\":\n",
    "        continue\n",
    "    cap = cv2.VideoCapture(\"../../data/pocus_videos/convex/\"+vid)\n",
    "    print(vid, [cap.get(i) for i in range(7)])\n",
    "    print(cap.get(4))\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pocovidnet.evaluate_video import VideoEvaluator\n",
    "from pocovidnet import VIDEO_MODEL_FACTORY\n",
    "from pocovidnet.videoto3d import Videoto3D\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, GlobalAveragePooling3D\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "class GenesisEvaluator():\n",
    "    def __init__(self, weights_dir=\"video_genesis_lr1e4\", ensemble=True, split=None, model_id=\"genesis\"):\n",
    "        \"\"\"\n",
    "        Constructor of COVID model evaluator class.\n",
    "        \n",
    "        Arguments:\n",
    "            ensemble {str} -- Whether the model ensemble is used.\n",
    "            num_classes: must be 3 or 4, how many classes the model was\n",
    "            trained on\n",
    "        \"\"\"\n",
    "        # self.root = os.path.join('/', *DIR_PATH.split('/')[:-1])\n",
    "        self.split = split\n",
    "        self.ensemble = ensemble\n",
    "        \n",
    "        if model_id not in VIDEO_MODEL_FACTORY.keys():\n",
    "            raise ValueError(\n",
    "                f'Wrong model {model_id}. Options are:{MODEL_FACTORY.keys()}'\n",
    "            )\n",
    "        else:\n",
    "            self.model_id = model_id\n",
    "\n",
    "        if ensemble:\n",
    "            # retores 5 weight paths\n",
    "            self.weights_paths = [\n",
    "                os.path.join(\n",
    "                    weights_dir, 'fold_' + str(fold), \"variables\",\n",
    "                    \"variables\"\n",
    "                ) for fold in range(NUM_FOLDS)\n",
    "            ]\n",
    "        else:\n",
    "            if split is None or split < 0 or split > 4:\n",
    "                raise ValueError(f'Provide split between 0 and 4, not {split}')\n",
    "            self.weights_paths = [\n",
    "                os.path.join(\n",
    "                    # self.root\n",
    "                    weights_dir, 'fold_' + str(self.split), \"variables\",\n",
    "                    \"variables\"\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.class_mappings = ['covid', 'pneunomia', 'regular']\n",
    "        # Get Genesis base model\n",
    "        base_models = [\n",
    "            VIDEO_MODEL_FACTORY[self.model_id](( 1, 64, 64, 32), batch_normalization=True)\n",
    "            for _ in range(len(self.weights_paths))\n",
    "        ]\n",
    "        # Get model head\n",
    "        self.models = []\n",
    "        for mod in base_models:\n",
    "            x = mod.get_layer('depth_7_relu').output\n",
    "            x = GlobalAveragePooling3D()(x)\n",
    "            x = Dense(1024, activation='relu')(x)\n",
    "            output = Dense(len(self.class_mappings), activation='softmax')(x)\n",
    "            head_model = Model(inputs=mod.input, outputs=output)\n",
    "            self.models.append(head_model)\n",
    "\n",
    "        # restore weights\n",
    "        try:\n",
    "            for model, path in zip(self.models, self.weights_paths):\n",
    "                model.load_weights(path)\n",
    "        except Exception:\n",
    "            raise Exception('Error in model restoring.')\n",
    "\n",
    "        print(f'Model restored. Class mappings are {self.class_mappings}')\n",
    "         \n",
    "    def __call__(self, video_path, width=64, depth=5, fr=5):\n",
    "        # read in video\n",
    "        vid3d = Videoto3D(\"\",width, width, depth, fr)\n",
    "        vid3d.max_vid = {\"cov\": 20, \"pne\": 20, \"reg\": 20}\n",
    "        X_test, _, fn = vid3d.video3d([video_path], [\"cov\"]) # cov as dummy label\n",
    "        print(X_test.shape)\n",
    "        assert len(np.unique(fn))==1\n",
    "\n",
    "        # prepare for genesis\n",
    "        input_shape = 42\n",
    "        input_shape = 1, 64, 64, 32\n",
    "\n",
    "        X_test = np.transpose(X_test, [0, 4, 2, 3, 1])\n",
    "        X_test = np.repeat(X_test, [6, 7, 7, 6, 6], axis=-1)\n",
    "        # res = self.models[0].predict(X_test[0])\n",
    "        res = [model.predict(X_test) for model in self.models]\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen = GenesisEvaluator(ensemble=False, split=0)\n",
    "gen(\"../../data/pocus_videos/convex/Pneu-Atlas-pneumonia.gif\")\n",
    "# prep_vid_snippets(\"../../data/pocus_videos/convex/\"+\"Pneu-Atlas-pneumonia.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/video_input_data/cross_val.json\", \"r\") as infile:\n",
    "    cross_val_split = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_DIR = \"../video_genesis_lr1e4\"\n",
    "VIDEO_DIR = \"../../data/pocus_videos/convex\"\n",
    "all_genesis_preds = []\n",
    "all_frame_preds = []\n",
    "for i in range(5):\n",
    "    # gen_eval = GenesisEvaluator(weights_dir = WEIGHTS_DIR, ensemble=False, split=i)\n",
    "    # normal_eval = VideoEvaluator(ensemble=False, split=i, model_id=\"vgg_cam\", num_classes=4)\n",
    "    files = cross_val_split[str(i)][\"test\"][0]\n",
    "    # print(files)\n",
    "    for f in files:\n",
    "        print(\"evaluate\", f)\n",
    "        # run genesis model\n",
    "        vid3d = Videoto3D(\"\", 64, 64, 5, 5)\n",
    "        vid3d.max_vid = {\"cov\": 20, \"pne\": 20, \"reg\": 20}\n",
    "        X_test, _, fn = vid3d.video3d(\n",
    "            [os.path.join(VIDEO_DIR, f)], [\"cov\"]\n",
    "        )  # cov as dummy label\n",
    "        print(X_test.shape)\n",
    "        assert len(np.unique(fn)) == 1\n",
    "        \n",
    "       # preds = gen_eval(os.path.join(VIDEO_DIR, f))\n",
    "       # vid_pred_genesis = np.argmax(np.mean(preds, axis=(0,1)))\n",
    "       # all_genesis_preds.append(preds)\n",
    "       # # run cam model\n",
    "       # preds_framebased = normal_eval(os.path.join(VIDEO_DIR, f))\n",
    "       # frame_pred = np.argmax(np.mean(preds_framebased, axis=(0,1)),1)\n",
    "       # all_frame_preds.append(preds_framebased)\n",
    "       # print(\"genesis pred\", vid_pred_genesis, \"frame based pred\", frame_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "baseModel = VGG16(\n",
    "    include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n",
    "    pooling=None, classes=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid3d = Videoto3D(\"\",64, 64, 5, 5)\n",
    "vid3d.max_vid = {\"cov\": 20, \"pne\": 20, \"reg\": 20}\n",
    "X_test, _, fn = vid3d.video3d([\"../../data/pocus_videos/convex/Reg-NormalLungs.mp4\"], [\"cov\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(fn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of video classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = cross_val_split[str(i)][\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_dict = {\"cov\":0, \"pne\":1, \"reg\":2}\n",
    "this_class = {\"cov\":\"covid\", \"pne\":\"pneumonia\", \"reg\":\"regular\"}\n",
    "saved_gt = []\n",
    "\n",
    "for i in range(5):\n",
    "    all_labels = []\n",
    "    files, labs = cross_val_split[str(i)][\"test\"]\n",
    "    for j in range(len(files)):\n",
    "        if not \"Butterfly\" in files[j]:\n",
    "            assert os.path.exists(os.path.join(\"../../data/cross_validation/split\"+str(i), this_class[labs[j]], files[j]+\"_frame0.jpg\")), files[j]+\"_\"+str(i)\n",
    "        if files[j]!= \"Reg-Youtube.mp4\" and files[j]!=\"Reg-NormalLungs.mp4\":\n",
    "            all_labels.append(lab_dict[labs[j]])\n",
    "    saved_gt.append(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.get(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "eval_path = \"evaluation_outputs.dat\"\n",
    "with open(eval_path, \"rb\") as infile:\n",
    "    vidbased, frame_based = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, classification_report, matthews_corrcoef, balanced_accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc_multiclass(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    mcc_out = []\n",
    "    for classe in np.unique(y_true):\n",
    "        y_true_binary = (y_true==classe).astype(int)\n",
    "        y_pred_binary = (y_pred==classe).astype(int)\n",
    "        mcc_out.append(matthews_corrcoef(y_true_binary, y_pred_binary))\n",
    "    return mcc_out\n",
    "def specificity(y_true, y_pred):\n",
    "    # true negatives / negatives\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    spec_out = []\n",
    "    for classe in np.unique(y_true):\n",
    "        negatives = np.sum((y_true!=classe).astype(int))\n",
    "        tn = np.sum((y_pred[y_true!=classe]!=classe).astype(int))\n",
    "        spec_out.append(tn/negatives)\n",
    "    return spec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = frame_based # , frame_based]):\n",
    "    \n",
    "saved_logits = [[] for _ in range(5)]\n",
    "split_counter = 0\n",
    "frame_counter = len(saved_gt[0])\n",
    "for vid_ind in range(len(vidbased)):\n",
    "    # print(frame_based[vid_ind].shape)\n",
    "    # print(vid_ind, split_counter)\n",
    "    saved_logits[split_counter].append(np.argmax(np.mean(classifier[vid_ind], axis=0)))\n",
    "    # saved_logits[split_counter].append(np.argmax(np.mean(classifier[vid_ind], axis=(0,1))))\n",
    "    if len(saved_logits[split_counter])==len(saved_gt[split_counter]):\n",
    "        # next cross val split\n",
    "        # print(vid_ind, len(saved_gt[split_counter]), split_counter)\n",
    "        frame_counter += len(saved_gt[split_counter])\n",
    "        split_counter += 1\n",
    "assert len(saved_logits[2])==len(saved_gt[2])\n",
    "\n",
    "all_reports = []\n",
    "accs = []\n",
    "bal_accs = []\n",
    "# vid_accs, _, vid_accs_bal, _ = video_accuracy(saved_logits, saved_gt, saved_files)\n",
    "for s in range(5):\n",
    "    gt_s = saved_gt[s]\n",
    "    print(len(gt_s), saved_logits[s])\n",
    "    pred_idx_s = saved_logits[s] # np.argmax(np.array(saved_logits[s]), axis=1)\n",
    "    report = classification_report(\n",
    "        gt_s, pred_idx_s, target_names=CLASSES, output_dict=True\n",
    "        )\n",
    "    mcc_scores = mcc_multiclass(gt_s, pred_idx_s)\n",
    "    spec_scores = specificity(gt_s, pred_idx_s)\n",
    "    for i, cl in enumerate(CLASSES):\n",
    "        report[cl][\"mcc\"] = mcc_scores[i]\n",
    "        report[cl][\"specificity\"] = spec_scores[i]\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df = df.drop(columns=\"support\")\n",
    "    df[\"accuracy\"] = [report[\"accuracy\"] for _ in range(len(df))]\n",
    "    bal = balanced_accuracy_score(gt_s, pred_idx_s)\n",
    "    df[\"balanced\"] = [bal for _ in range(len(df))]\n",
    "    # df[\"video\"] = vid_accs[s]\n",
    "    # df[\"video_balanced\"] = vid_accs_bal[s]\n",
    "    # print(df[:len(CLASSES)])\n",
    "    #print(report[\"accuracy\"])\n",
    "    # print(np.array(df)[:3,:])\n",
    "    accs.append(report[\"accuracy\"])\n",
    "    bal_accs.append(balanced_accuracy_score(gt_s, pred_idx_s))\n",
    "    # df = np.array(report)\n",
    "    all_reports.append(np.array(df)[:len(CLASSES)])\n",
    "df_arr = np.around(np.mean(all_reports, axis=0), 2)\n",
    "df_classes = pd.DataFrame(df_arr, columns=[\"Precision\", \"Recall\", \"F1-score\", \"MCC\", \"Specificity\", \"Accuracy\", \"Balanced\"], index=CLASSES)\n",
    "print(df_classes)\n",
    "df_std = np.around(np.std(all_reports, axis=0), 2)\n",
    "df_std = pd.DataFrame(df_std, columns=[\"Precision\", \"Recall\", \"F1-score\", \"MCC\", \"Specificity\", \"Accuracy\", \"Balanced\"], index=CLASSES)\n",
    "\n",
    "df_classes = df_classes[[\"Accuracy\", \"Balanced\", \"Precision\", \"Recall\",\"Specificity\", \"F1-score\", \"MCC\"]]\n",
    "df_std = df_std[[\"Accuracy\", \"Balanced\", \"Precision\", \"Recall\",\"Specificity\", \"F1-score\", \"MCC\"]]\n",
    "\n",
    "# df_classes.to_csv(\"model_comparison/vid_cam_3_mean.csv\")\n",
    "# df_std.to_csv(\"model_comparison/vid_cam_3_std.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
