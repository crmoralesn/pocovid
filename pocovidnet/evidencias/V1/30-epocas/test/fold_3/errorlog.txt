(base) PS D:\Fuentes\Bnamericas\covid19_ultrasound\pocovidnet>  python scripts/train_covid19.py --data_dir ../data/cross_validation/ --fold 3 --epochs 30 -m data/V1/30-epocas
2021-03-29 17:05:17.162107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
Model parameters: {'data_dir': '../data/cross_validation/', 'model_dir': 'data/V1/30-epocas', 'fold': 3, 'learning_rate': 0.0001, 'epochs': 30, 'batch_size': 16, 'trainable_base_layers': 1, 'img_width': 224, 'img_height': 224, 'model_id': 'vgg_base', 'log_softmax': False, 'model_name': 'test', 'hidden_size': 64}
Loading images...
selected fold: 3

Number of training samples: 1690
Number of testing samples: 459
Class mappings are: ['covid' 'pneumonia' 'regular']
2021-03-29 17:05:33.940355: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-03-29 17:05:33.942419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-03-29 17:05:34.905842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2021-03-29 17:05:34.906151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-03-29 17:05:34.929463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-03-29 17:05:34.929744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-03-29 17:05:34.939454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-03-29 17:05:34.943817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-03-29 17:05:34.953647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-03-29 17:05:34.961889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-03-29 17:05:34.964590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-03-29 17:05:34.964878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 17:05:34.966254: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-03-29 17:05:34.967148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2021-03-29 17:05:34.967410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-03-29 17:05:34.968132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-03-29 17:05:34.968788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-03-29 17:05:34.973429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-03-29 17:05:34.977118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-03-29 17:05:34.977735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-03-29 17:05:34.978410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-03-29 17:05:34.979014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-03-29 17:05:34.979902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-03-29 17:05:35.831963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-29 17:05:35.832142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2021-03-29 17:05:35.834454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N
2021-03-29 17:05:35.838938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2987 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
2021-03-29 17:05:35.840598: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
Compiling model...
Model has 14747971 parameters
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 224, 224, 3)]     0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
average_pooling2d (AveragePo (None, 1, 1, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 512)               0
_________________________________________________________________
dense (Dense)                (None, 64)                32832
_________________________________________________________________
batch_normalization (BatchNo (None, 64)                256
_________________________________________________________________
re_lu (ReLU)                 (None, 64)                0
_________________________________________________________________
dropout (Dropout)            (None, 64)                0
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 195
=================================================================
Total params: 14,747,971
Trainable params: 2,392,963
Non-trainable params: 12,355,008
_________________________________________________________________
Model summary None
Starting training model...
d:\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`Model.fit_generator` is deprecated and '
2021-03-29 17:05:37.540419: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
Epoch 1/30
2021-03-29 17:05:39.375371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-03-29 17:05:39.893002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-03-29 17:05:40.052603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-03-29 17:05:41.067055: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2021-03-29 17:05:41.172577: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2021-03-29 17:05:42.461995: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
105/105 [==============================] - ETA: 0s - loss: 0.9631 - accuracy: 0.59362021-03-29 17:06:26.836074: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
105/105 [==============================] - 62s 484ms/step - loss: 0.9614 - accuracy: 0.5946 - val_loss: 1.0496 - val_accuracy: 0.3007

Epoch 00001: val_accuracy improved from -inf to 0.30065, saving model to data/V1/30-epocas\test\fold_3\best_weights
2021-03-29 17:06:40.782881: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2021-03-29 17:06:48.109132: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-29 17:06:48.109582: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-29 17:06:48.212747: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-29 17:06:51.740443: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Balanced accuracy is: {'val_balanced': 0.35919581291925834}
Epoch 2/30
105/105 [==============================] - 32s 299ms/step - loss: 0.4689 - accuracy: 0.8336
Balanced accuracy is: {'val_balanced': 0.5707514121199646}
Epoch 3/30
105/105 [==============================] - 32s 304ms/step - loss: 0.4160 - accuracy: 0.8499
Balanced accuracy is: {'val_balanced': 0.4897911264792401}
Epoch 4/30
105/105 [==============================] - 33s 312ms/step - loss: 0.3474 - accuracy: 0.8758
Balanced accuracy is: {'val_balanced': 0.5402822708152222}
Epoch 5/30
105/105 [==============================] - 33s 315ms/step - loss: 0.3064 - accuracy: 0.9022
Balanced accuracy is: {'val_balanced': 0.5953120911545758}
Epoch 6/30
105/105 [==============================] - 33s 314ms/step - loss: 0.2978 - accuracy: 0.8929
Balanced accuracy is: {'val_balanced': 0.723862797272262}
Epoch 7/30
105/105 [==============================] - 32s 307ms/step - loss: 0.2867 - accuracy: 0.9061
Balanced accuracy is: {'val_balanced': 0.5162887689066911}
Epoch 8/30
105/105 [==============================] - 32s 307ms/step - loss: 0.2566 - accuracy: 0.9240
Balanced accuracy is: {'val_balanced': 0.5269094386205446}
Epoch 9/30
105/105 [==============================] - 33s 313ms/step - loss: 0.2201 - accuracy: 0.9301
Balanced accuracy is: {'val_balanced': 0.5969743838637163}
Epoch 10/30
105/105 [==============================] - 34s 320ms/step - loss: 0.2409 - accuracy: 0.9213
Balanced accuracy is: {'val_balanced': 0.5440915692047371}
Epoch 11/30
105/105 [==============================] - 33s 313ms/step - loss: 0.2369 - accuracy: 0.9268
Balanced accuracy is: {'val_balanced': 0.6467223016438065}
Epoch 12/30
105/105 [==============================] - 34s 317ms/step - loss: 0.2157 - accuracy: 0.9409
Balanced accuracy is: {'val_balanced': 0.6157879617861526}
Epoch 13/30
105/105 [==============================] - 33s 315ms/step - loss: 0.1902 - accuracy: 0.9408
Balanced accuracy is: {'val_balanced': 0.5937276462862698}
Epoch 14/30
105/105 [==============================] - 34s 321ms/step - loss: 0.1913 - accuracy: 0.9350
Balanced accuracy is: {'val_balanced': 0.5190631736277534}
Epoch 15/30
105/105 [==============================] - 33s 317ms/step - loss: 0.1490 - accuracy: 0.9595
Balanced accuracy is: {'val_balanced': 0.5048117729436576}
Epoch 16/30
105/105 [==============================] - 33s 315ms/step - loss: 0.1727 - accuracy: 0.9513
Balanced accuracy is: {'val_balanced': 0.6676253911539254}
Epoch 17/30
105/105 [==============================] - 33s 317ms/step - loss: 0.1840 - accuracy: 0.9420
Balanced accuracy is: {'val_balanced': 0.6421796388237883}
Epoch 18/30
105/105 [==============================] - 34s 318ms/step - loss: 0.1610 - accuracy: 0.9468
Balanced accuracy is: {'val_balanced': 0.5655173513604592}
Epoch 19/30
105/105 [==============================] - 33s 312ms/step - loss: 0.1213 - accuracy: 0.9689
Balanced accuracy is: {'val_balanced': 0.5076856382484278}
Epoch 20/30
105/105 [==============================] - 33s 312ms/step - loss: 0.1654 - accuracy: 0.9569
Balanced accuracy is: {'val_balanced': 0.5353797453347425}
Epoch 21/30
105/105 [==============================] - 33s 313ms/step - loss: 0.1531 - accuracy: 0.9527
Balanced accuracy is: {'val_balanced': 0.6601519984338106}
Epoch 22/30
105/105 [==============================] - 33s 316ms/step - loss: 0.1365 - accuracy: 0.9567
Balanced accuracy is: {'val_balanced': 0.5390438396653424}
Epoch 23/30
105/105 [==============================] - 33s 312ms/step - loss: 0.1200 - accuracy: 0.9701
Balanced accuracy is: {'val_balanced': 0.6255745474910648}
Epoch 24/30
105/105 [==============================] - 34s 322ms/step - loss: 0.1452 - accuracy: 0.9577
Balanced accuracy is: {'val_balanced': 0.5704393912592612}
Epoch 25/30
105/105 [==============================] - 34s 318ms/step - loss: 0.1242 - accuracy: 0.9658
Balanced accuracy is: {'val_balanced': 0.5866546138904468}
Epoch 26/30
105/105 [==============================] - 35s 323ms/step - loss: 0.1506 - accuracy: 0.9481
Balanced accuracy is: {'val_balanced': 0.5601576009603612}
Epoch 27/30
105/105 [==============================] - 34s 323ms/step - loss: 0.1300 - accuracy: 0.9651
Balanced accuracy is: {'val_balanced': 0.504955088510477}
Epoch 28/30
105/105 [==============================] - 33s 317ms/step - loss: 0.1469 - accuracy: 0.9575
Balanced accuracy is: {'val_balanced': 0.5309634016526824}
Epoch 29/30
105/105 [==============================] - 34s 324ms/step - loss: 0.1161 - accuracy: 0.9715
Balanced accuracy is: {'val_balanced': 0.5319303096056891}
Epoch 30/30
105/105 [==============================] - 34s 318ms/step - loss: 0.0947 - accuracy: 0.9793
Balanced accuracy is: {'val_balanced': 0.5086865390591574}
Evaluating network...
classification report sklearn:
              precision    recall  f1-score   support

       covid       1.00      0.06      0.11        53
   pneumonia       0.41      0.67      0.51        97
     regular       0.83      0.80      0.82       309

    accuracy                           0.69       459
   macro avg       0.75      0.51      0.48       459
weighted avg       0.76      0.69      0.67       459

confusion matrix:
[[  3  32  18]
 [  0  65  32]
 [  0  62 247]]
Inicio gráfico
cantidad de epocas: 30
Fin gráfico
inicio data
accuracy: [0.6977300047874451, 0.8297491073608398, 0.8542413115501404, 0.882915198802948, 0.8936678767204285, 0.8966547250747681, 0.918757438659668, 0.9259259104728699, 0.9247311949729919, 0.924133837223053, 0.9235364198684692, 0.9468339085578918, 0.9414575695991516, 0.9408602118492126, 0.9504181742668152, 0.9456391930580139, 0.9426523447036743, 0.9528076648712158, 0.9629629850387573, 0.9563918709754944, 0.959378719329834, 0.9605734944343567, 0.9707288146018982, 0.958184003829956, 0.9617682099342346, 0.9551971554756165, 0.9575866460800171, 0.959976077079773, 0.9695340394973755, 0.9707288146018982]
loss: [0.7775278091430664, 0.4763523042201996, 0.40243759751319885, 0.33655908703804016, 0.32461977005004883, 0.28773048520088196, 0.26455196738243103, 0.25041189789772034, 0.2363794445991516, 0.23195120692253113, 0.23994675278663635, 0.2052011638879776, 0.1880812793970108, 0.18761439621448517, 0.16088013350963593, 0.17536625266075134, 0.18367153406143188, 0.15177099406719208, 0.13456667959690094, 0.1555480808019638, 0.14183850586414337, 0.13009747862815857, 0.11594793945550919, 0.1491740345954895, 0.1281009316444397, 0.13661246001720428, 0.14341723918914795, 0.13844464719295502, 0.12033101916313171, 0.10373585671186447]
Traceback (most recent call last):
  File "scripts/train_covid19.py", line 283, in <module>
    print(f'val_accuracy: {val_accuracy}')
NameError: name 'val_accuracy' is not defined
convert the history.history dict to a pandas DataFrame:
No se pudo guardar la data
Traceback (most recent call last):
  File "scripts/train_covid19.py", line 294, in <module>
    hist_df = pd.DataFrame(H.history)
  File "d:\anaconda3\lib\site-packages\pandas\core\frame.py", line 468, in __init__
    mgr = init_dict(data, index, columns, dtype=dtype)
  File "d:\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 283, in init_dict
    return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype)
  File "d:\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 78, in arrays_to_mgr
    index = extract_index(arrays)
  File "d:\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 397, in extract_index
    raise ValueError("arrays must all be same length")
ValueError: arrays must all be same length
Done, shuttting down!
Done, shuttting down!